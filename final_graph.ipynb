{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Notebook for BTCGraphGuard\n",
    "\n",
    "**Authors: Xuhui Zhan, Tianhao Qu, Siyu Yang**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T01:48:15.088529Z",
     "start_time": "2025-04-07T01:48:15.084030Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.utils import from_networkx\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T00:55:21.950839Z",
     "start_time": "2025-04-07T00:55:18.838962Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare Data\n",
    "data_root = 'data/elliptic_bitcoin_dataset'\n",
    "elliptic_txs_features = pd.read_csv(os.path.join(data_root, 'elliptic_txs_features.csv'), header=None)\n",
    "elliptic_txs_edgelist = pd.read_csv(os.path.join(data_root, 'elliptic_txs_edgelist.csv'))\n",
    "elliptic_txs_classes = pd.read_csv(os.path.join(data_root, 'elliptic_txs_classes.csv'))\n",
    "\n",
    "elliptic_txs_features.columns = ['txId'] + [f'V{i}' for i in range(1, 167)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T00:55:23.908129Z",
     "start_time": "2025-04-07T00:55:23.905040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(203769, 167)\n",
      "(234355, 2)\n",
      "(203769, 2)\n"
     ]
    }
   ],
   "source": [
    "print(elliptic_txs_features.shape)\n",
    "print(elliptic_txs_edgelist.shape)\n",
    "print(elliptic_txs_classes.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T01:09:33.195956Z",
     "start_time": "2025-04-07T01:09:33.171203Z"
    }
   },
   "outputs": [],
   "source": [
    "elliptic_txs_classes['class_mapped'] = elliptic_txs_classes['class'].replace({'1': 'illicit', '2': 'licit'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T01:09:34.482266Z",
     "start_time": "2025-04-07T01:09:33.723713Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create Graph\n",
    "G = nx.from_pandas_edgelist(elliptic_txs_edgelist, 'txId1', 'txId2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random seed settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T01:09:36.155117Z",
     "start_time": "2025-04-07T01:09:36.152694Z"
    }
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "NUM_EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T01:09:36.907170Z",
     "start_time": "2025-04-07T01:09:36.903171Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_seed_for_torch(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)      # For single-GPU.\n",
    "        torch.cuda.manual_seed_all(seed)  # For multi-GPU.\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "def set_seed_for_numpy(seed):\n",
    "    np.random.seed(seed) \n",
    "    \n",
    "def set_seed_for_random(seed):\n",
    "    random.seed(seed)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T01:09:37.807822Z",
     "start_time": "2025-04-07T01:09:37.798822Z"
    }
   },
   "outputs": [],
   "source": [
    "set_seed_for_torch(RANDOM_STATE)\n",
    "set_seed_for_numpy(RANDOM_STATE)\n",
    "set_seed_for_random(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T21:45:13.356208Z",
     "start_time": "2025-04-05T21:45:13.345483Z"
    }
   },
   "outputs": [],
   "source": [
    "# Spaceholders for EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T01:10:22.940488Z",
     "start_time": "2025-04-07T01:10:22.742410Z"
    }
   },
   "outputs": [],
   "source": [
    "tx_id_mapping = {tx_id: idx for idx, tx_id in enumerate(elliptic_txs_features['txId'])}\n",
    "\n",
    "# Create an explicit copy of the filtered DataFrame\n",
    "edges_with_features = elliptic_txs_edgelist[elliptic_txs_edgelist['txId1'].isin(list(tx_id_mapping.keys())) & \n",
    "                                           elliptic_txs_edgelist['txId2'].isin(list(tx_id_mapping.keys()))].copy()\n",
    "\n",
    "# Now use loc to set values (though with copy() above, direct assignment would also work)\n",
    "edges_with_features.loc[:, 'Id1'] = edges_with_features['txId1'].map(tx_id_mapping)\n",
    "edges_with_features.loc[:, 'Id2'] = edges_with_features['txId2'].map(tx_id_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T01:10:23.654842Z",
     "start_time": "2025-04-07T01:10:23.548299Z"
    }
   },
   "outputs": [],
   "source": [
    "edge_index = torch.tensor(edges_with_features[['Id1', 'Id2']].values.T, dtype=torch.long)\n",
    "node_features = torch.tensor(elliptic_txs_features.drop(columns=['txId']).values, \n",
    "                             dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T01:10:24.115669Z",
     "start_time": "2025-04-07T01:10:24.093341Z"
    }
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "class_labels = le.fit_transform(elliptic_txs_classes['class'])\n",
    "node_labels = torch.tensor(class_labels, dtype=torch.long)\n",
    "original_labels = le.inverse_transform(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T01:10:24.812006Z",
     "start_time": "2025-04-07T01:10:24.809006Z"
    }
   },
   "outputs": [],
   "source": [
    "data = Data(x=node_features, \n",
    "            edge_index=edge_index, \n",
    "            y=node_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T01:10:25.511512Z",
     "start_time": "2025-04-07T01:10:25.508672Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T01:10:28.084388Z",
     "start_time": "2025-04-07T01:10:28.078385Z"
    }
   },
   "outputs": [],
   "source": [
    "known_mask   = (data.y == 0) | (data.y == 1)  # Only nodes with known labels licit or illicit\n",
    "unknown_mask = data.y == 2                    # Nodes with unknown labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T01:10:29.067259Z",
     "start_time": "2025-04-07T01:10:29.059912Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations per split\n",
      "    Training   :     37,251 (80.00 %)\n",
      "    Validation :      4,656 (10.00 %)\n",
      "    Testing    :      4,657 (10.00 %)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_known_nodes = known_mask.sum().item()\n",
    "permutations = torch.randperm(num_known_nodes)\n",
    "train_size = int(0.8 * num_known_nodes)\n",
    "val_size = int(0.1 * num_known_nodes)\n",
    "test_size = num_known_nodes - train_size - val_size\n",
    "\n",
    "total = np.sum([train_size, val_size, test_size])\n",
    "\n",
    "print(f\"\"\"Number of observations per split\n",
    "    Training   : {train_size:10,} ({100*train_size/total:0.2f} %)\n",
    "    Validation : {val_size:10,} ({100*val_size/total:0.2f} %)\n",
    "    Testing    : {test_size:10,} ({100*test_size/total:0.2f} %)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T01:10:29.957245Z",
     "start_time": "2025-04-07T01:10:29.941750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203769\n"
     ]
    }
   ],
   "source": [
    "data.train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "data.val_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "data.test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "\n",
    "train_indices = known_mask.nonzero(as_tuple=True)[0][permutations[:train_size]]\n",
    "val_indices = known_mask.nonzero(as_tuple=True)[0][permutations[train_size:train_size + val_size]]\n",
    "test_indices = known_mask.nonzero(as_tuple=True)[0][permutations[train_size + val_size:]]\n",
    "\n",
    "data.train_mask[train_indices] = True\n",
    "data.val_mask[val_indices] = True\n",
    "data.test_mask[test_indices] = True\n",
    "\n",
    "print(len(data.train_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_mask', 'x', 'test_mask', 'edge_index', 'y', 'val_mask']\n"
     ]
    }
   ],
   "source": [
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph attention network (GAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, heads=8):\n",
    "        super(GAT, self).__init__()\n",
    "        self.conv1 = GATConv(input_dim, hidden_dim, heads=heads, dropout=0.6)\n",
    "        self.conv2 = GATConv(hidden_dim * heads, output_dim, heads=1, concat=False, dropout=0.6)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(input_dim, hidden_dim)\n",
    "        self.conv2 = SAGEConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gnn_model(graph_data, checkpoint_path, model_args=None, num_epochs=200, lr=0.005, weight_decay=5e-4, verbose=True):\n",
    "    \"\"\"\n",
    "    Train a Graph Neural Network model and save checkpoints.\n",
    "    \n",
    "    Args:\n",
    "        graph_data (torch_geometric.data.Data): The prepared graph data\n",
    "        checkpoint_path (str): Path to save model checkpoints\n",
    "        model_args (dict, optional): Dictionary containing model parameters:\n",
    "            - model_name: Type of GNN model ('GAT' or 'GraphSAGE')\n",
    "            - input_dim: Input feature dimension\n",
    "            - hidden_dim: Hidden layer dimension\n",
    "            - output_dim: Output dimension (number of classes)\n",
    "            - heads: Number of attention heads (for GAT, default: 8)\n",
    "        num_epochs (int): Maximum number of training epochs\n",
    "        lr (float): Learning rate for Adam optimizer\n",
    "        weight_decay (float): Weight decay for regularization\n",
    "        verbose (bool): Whether to print training progress\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing trained model and training metrics\n",
    "    \"\"\"\n",
    "    # Set up device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
    "    \n",
    "    # Move data to device\n",
    "    graph_data = graph_data.to(device)\n",
    "    \n",
    "    # Set default model args if not provided\n",
    "    if model_args is None:\n",
    "        model_args = {\n",
    "            'model_name': 'GAT',  # Default to GAT if not specified\n",
    "            'input_dim': graph_data.x.shape[1],\n",
    "            'hidden_dim': 64,\n",
    "            'output_dim': len(torch.unique(graph_data.y[graph_data.y != 2])),  # Exclude unknown class\n",
    "            'heads': 8\n",
    "        }\n",
    "    \n",
    "    # Initialize model based on model_name\n",
    "    model_name = model_args.get('model_name', 'GAT')\n",
    "    \n",
    "    if model_name.upper() == 'GAT':\n",
    "        model = GAT(\n",
    "            input_dim=model_args['input_dim'],\n",
    "            hidden_dim=model_args['hidden_dim'],\n",
    "            output_dim=model_args['output_dim'],\n",
    "            heads=model_args.get('heads', 8)\n",
    "        ).to(device)\n",
    "        model_type = 'GAT'\n",
    "    elif model_name.upper() == 'GRAPHSAGE' or model_name.upper() == 'SAGE':\n",
    "        model = GraphSAGE(\n",
    "            input_dim=model_args['input_dim'],\n",
    "            hidden_dim=model_args['hidden_dim'],\n",
    "            output_dim=model_args['output_dim']\n",
    "        ).to(device)\n",
    "        model_type = 'GraphSAGE'\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model type: {model_name}. Use 'GAT' or 'GraphSAGE'.\")\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Training function\n",
    "    def train_step():\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(graph_data)\n",
    "        loss = criterion(out[graph_data.train_mask], graph_data.y[graph_data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        return loss.item()\n",
    "    \n",
    "    # Evaluation function\n",
    "    def evaluate(mask):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            out = model(graph_data)\n",
    "            pred = out.argmax(dim=1)\n",
    "            correct = pred[mask] == graph_data.y[mask]\n",
    "            acc = int(correct.sum()) / int(mask.sum())\n",
    "        return acc\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_acc = 0\n",
    "    best_model_state = None\n",
    "    train_history = {\n",
    "        'losses': [],\n",
    "        'train_acc': [],\n",
    "        'val_acc': []\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        loss = train_step()\n",
    "        train_acc = evaluate(graph_data.train_mask)\n",
    "        val_acc = evaluate(graph_data.val_mask)\n",
    "        \n",
    "        train_history['losses'].append(loss)\n",
    "        train_history['train_acc'].append(train_acc)\n",
    "        train_history['val_acc'].append(val_acc)\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model_state = model.state_dict()\n",
    "            torch.save(best_model_state, checkpoint_path)\n",
    "            \n",
    "        if verbose and epoch % 10 == 0:\n",
    "            print(f'{model_type} Epoch: {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Load best model and evaluate\n",
    "    model.load_state_dict(best_model_state)\n",
    "    test_acc = evaluate(graph_data.test_mask)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'{model_type} Test Accuracy: {test_acc:.4f}')\n",
    "        print(f'{model_type} Training Time: {training_time:.2f} seconds')\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'best_model_state': best_model_state,\n",
    "        'test_accuracy': test_acc,\n",
    "        'val_accuracy': best_val_acc,\n",
    "        'training_time': training_time,\n",
    "        'training_history': train_history\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_model_results(results, save_dir=None, model_name=\"model\"):\n",
    "    \"\"\"\n",
    "    Inspects and visualizes the results from the train_gnn_model function.\n",
    "    \n",
    "    Args:\n",
    "        results (dict): Results dictionary returned by train_gnn_model\n",
    "        save_dir (str, optional): Directory to save visualizations and metrics\n",
    "                                 If None, extracts directory from checkpoint path\n",
    "        model_name (str): Name of the model for labeling plots and files\n",
    "    \"\"\"\n",
    "    # Extract training history and metrics\n",
    "    history = results['training_history']\n",
    "    test_acc = results['test_accuracy']\n",
    "    val_acc = results['val_accuracy']\n",
    "    training_time = results['training_time']\n",
    "    \n",
    "    # Determine save directory\n",
    "    if save_dir is None:\n",
    "        if 'best_model_state' in results and isinstance(results['best_model_state'], str):\n",
    "            save_dir = os.path.dirname(results['best_model_state'])\n",
    "        else:\n",
    "            save_dir = 'output'\n",
    "    \n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Create figure with 2 subplots\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    # Plot training loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    epochs = range(1, len(history['losses']) + 1)\n",
    "    plt.plot(epochs, history['losses'], 'bo-', label='Training Loss')\n",
    "    plt.title(f'{model_name} - Training Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Plot training and validation accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, history['train_acc'], 'go-', label='Training Accuracy')\n",
    "    plt.plot(epochs, history['val_acc'], 'ro-', label='Validation Accuracy')\n",
    "    plt.title(f'{model_name} - Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Save figure\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, f'{model_name}_training_history.png'), dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # Print and save metrics\n",
    "    metrics = {\n",
    "        'Model': model_name,\n",
    "        'Test Accuracy': f'{test_acc:.4f}',\n",
    "        'Validation Accuracy': f'{val_acc:.4f}',\n",
    "        'Training Time (s)': f'{training_time:.2f}',\n",
    "        'Final Training Loss': f'{history[\"losses\"][-1]:.4f}',\n",
    "        'Number of Epochs': len(history['losses'])\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{'='*20} {model_name} Results {'='*20}\")\n",
    "    for key, value in metrics.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Save metrics to CSV\n",
    "    pd.DataFrame([metrics]).to_csv(os.path.join(save_dir, f'{model_name}_metrics.csv'), index=False)\n",
    "    \n",
    "    # Create additional visualization: accuracy vs loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(history['losses'], history['val_acc'], c=range(len(history['losses'])), cmap='viridis', \n",
    "                s=100, alpha=0.7, edgecolors='black', linewidth=1)\n",
    "    plt.colorbar(label='Epoch')\n",
    "    plt.title(f'{model_name} - Validation Accuracy vs Training Loss')\n",
    "    plt.xlabel('Training Loss')\n",
    "    plt.ylabel('Validation Accuracy')\n",
    "    plt.grid(True, linestyle='--', alpha=0.3)\n",
    "    plt.savefig(os.path.join(save_dir, f'{model_name}_acc_vs_loss.png'), dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_dim = data.x.shape[1]\n",
    "# hidden_dim = 64\n",
    "# output_dim = len(torch.unique(data.y[data.y != 2]))\n",
    "\n",
    "# gat_output_dir = 'output/GAT'\n",
    "\n",
    "# # For GAT model\n",
    "# gat_args = {\n",
    "#     'model_name': 'GAT',\n",
    "#     'input_dim': input_dim,\n",
    "#     'hidden_dim': hidden_dim,\n",
    "#     'output_dim': output_dim,\n",
    "#     'heads': 8\n",
    "# }\n",
    "\n",
    "# gat_results = train_gnn_model(\n",
    "#     graph_data=data,\n",
    "#     checkpoint_path=os.path.join(gat_output_dir, \"gat_best_model.pt\"),\n",
    "#     model_args=gat_args,\n",
    "#     num_epochs=200,\n",
    "#     verbose=True\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sage_output_dir = 'output/GraphSAGE'\n",
    "\n",
    "# # For GraphSAGE model\n",
    "# sage_args = {\n",
    "#     'model_name': 'GraphSAGE',\n",
    "#     'input_dim': input_dim,\n",
    "#     'hidden_dim': hidden_dim,\n",
    "#     'output_dim': output_dim\n",
    "# }\n",
    "\n",
    "# sage_results = train_gnn_model(\n",
    "#     graph_data=data,\n",
    "#     checkpoint_path=os.path.join(sage_output_dir, \"sage_best_model.pt\"),\n",
    "#     model_args=sage_args,\n",
    "#     num_epochs=200,\n",
    "#     verbose=True\n",
    "# )\n",
    "\n",
    "# metrics = inspect_model_results(sage_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmented Graph labels by self-supervised-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_labels(data, percentage=0.3, model=None):\n",
    "    \"\"\"\n",
    "    Augments the training data by adding predicted labels for previously unknown nodes.\n",
    "    \n",
    "    Args:\n",
    "        data (torch_geometric.data.Data): The input graph data\n",
    "        percentage (float, optional): Percentage of unknown nodes to add to training. Defaults to 0.3.\n",
    "        model (torch.nn.Module, optional): Pre-trained model to use for predictions. If None,\n",
    "                                          uses label propagation for self-supervised learning.\n",
    "    \n",
    "    Returns:\n",
    "        torch_geometric.data.Data: Augmented data with expanded training set\n",
    "    \"\"\"\n",
    "    # Create a copy of the data to avoid modifying the original\n",
    "    augmented_data = data.clone()\n",
    "    device = augmented_data.x.device\n",
    "    \n",
    "    # Get masks for known and unknown labels\n",
    "    known_mask = (augmented_data.y == 0) | (augmented_data.y == 1)\n",
    "    unknown_mask = augmented_data.y == 2\n",
    "    \n",
    "    # Count unknown nodes and calculate how many to add\n",
    "    num_unknown = unknown_mask.sum().item()\n",
    "    num_to_add = int(num_unknown * percentage)\n",
    "    \n",
    "    if model is None:\n",
    "        # Self-supervised learning approach using simple propagation\n",
    "        print(f\"Using self-supervised learning for label augmentation\")\n",
    "        \n",
    "        # Create graph from data\n",
    "        G = nx.Graph()\n",
    "        edge_index = augmented_data.edge_index.cpu().numpy()\n",
    "        \n",
    "        # Add nodes and edges to the graph\n",
    "        for i in range(augmented_data.num_nodes):\n",
    "            G.add_node(i)\n",
    "            \n",
    "        for i in range(edge_index.shape[1]):\n",
    "            G.add_edge(edge_index[0, i], edge_index[1, i])\n",
    "        \n",
    "        # Simple label propagation implementation\n",
    "        predicted_labels = torch.zeros_like(augmented_data.y)\n",
    "        confidence_scores = torch.zeros(len(augmented_data.y))\n",
    "        \n",
    "        # For each unknown node, check neighbors' labels\n",
    "        for node in range(len(augmented_data.y)):\n",
    "            if unknown_mask[node]:\n",
    "                # Get all neighbors\n",
    "                neighbors = list(G.neighbors(node))\n",
    "                if not neighbors:\n",
    "                    continue\n",
    "                \n",
    "                # Count labels of neighbors\n",
    "                label_count = {0: 0, 1: 0}\n",
    "                neighbor_features = []\n",
    "                \n",
    "                for neighbor in neighbors:\n",
    "                    if known_mask[neighbor]:\n",
    "                        neighbor_label = augmented_data.y[neighbor].item()\n",
    "                        label_count[neighbor_label] = label_count.get(neighbor_label, 0) + 1\n",
    "                        neighbor_features.append(augmented_data.x[neighbor])\n",
    "                \n",
    "                # If we have neighbors with known labels\n",
    "                if sum(label_count.values()) > 0:\n",
    "                    # Assign most frequent label\n",
    "                    if label_count[0] > label_count[1]:\n",
    "                        predicted_labels[node] = 0\n",
    "                        confidence_scores[node] = label_count[0] / (label_count[0] + label_count[1])\n",
    "                    elif label_count[1] > 0:\n",
    "                        predicted_labels[node] = 1\n",
    "                        confidence_scores[node] = label_count[1] / (label_count[0] + label_count[1])\n",
    "                else:\n",
    "                    # If no neighbors have known labels, look at second-degree neighbors\n",
    "                    second_degree_neighbors = []\n",
    "                    for neighbor in neighbors:\n",
    "                        second_degree_neighbors.extend(list(G.neighbors(neighbor)))\n",
    "                    \n",
    "                    # Remove duplicates and the original node\n",
    "                    second_degree_neighbors = list(set(second_degree_neighbors))\n",
    "                    if node in second_degree_neighbors:\n",
    "                        second_degree_neighbors.remove(node)\n",
    "                    \n",
    "                    # Count labels of second-degree neighbors\n",
    "                    second_label_count = {0: 0, 1: 0}\n",
    "                    for neighbor in second_degree_neighbors:\n",
    "                        if known_mask[neighbor]:\n",
    "                            neighbor_label = augmented_data.y[neighbor].item()\n",
    "                            second_label_count[neighbor_label] = second_label_count.get(neighbor_label, 0) + 1\n",
    "                    \n",
    "                    # Assign most frequent label from second-degree neighbors\n",
    "                    if sum(second_label_count.values()) > 0:\n",
    "                        if second_label_count[0] > second_label_count[1]:\n",
    "                            predicted_labels[node] = 0\n",
    "                            confidence_scores[node] = second_label_count[0] / (second_label_count[0] + second_label_count[1])\n",
    "                        elif second_label_count[1] > 0:\n",
    "                            predicted_labels[node] = 1\n",
    "                            confidence_scores[node] = second_label_count[1] / (second_label_count[0] + second_label_count[1])\n",
    "    else:\n",
    "        # Use the provided model for predictions\n",
    "        print(f\"Using provided model for label augmentation\")\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            out = model(augmented_data)\n",
    "            probabilities = F.softmax(out, dim=1)\n",
    "            \n",
    "            # Get the highest probability and corresponding class\n",
    "            confidence_scores, predicted_labels = probabilities.max(dim=1)\n",
    "    \n",
    "    # Select the top confident predictions among unknown nodes\n",
    "    unknown_indices = unknown_mask.nonzero(as_tuple=True)[0]\n",
    "    unknown_confidence = confidence_scores[unknown_indices]\n",
    "    \n",
    "    # Sort by confidence\n",
    "    sorted_indices = unknown_confidence.argsort(descending=True)\n",
    "    top_indices = unknown_indices[sorted_indices[:num_to_add]]\n",
    "    \n",
    "    # Update labels and training mask for selected nodes\n",
    "    augmented_data.y[top_indices] = predicted_labels[top_indices]\n",
    "    augmented_data.train_mask[top_indices] = True\n",
    "    \n",
    "    # Print statistics\n",
    "    added_illicit = (predicted_labels[top_indices] == 1).sum().item()\n",
    "    added_licit = (predicted_labels[top_indices] == 0).sum().item()\n",
    "    \n",
    "    print(f\"Added {num_to_add} previously unknown nodes to training set:\")\n",
    "    print(f\"  - Predicted illicit: {added_illicit} ({100*added_illicit/num_to_add:.2f}%)\")\n",
    "    print(f\"  - Predicted licit: {added_licit} ({100*added_licit/num_to_add:.2f}%)\")\n",
    "    \n",
    "    return augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment_data = augment_labels(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sage_model = GraphSAGE(input_dim, hidden_dim, output_dim)\n",
    "# sage_model.load_state_dict(torch.load(os.path.join(sage_output_dir, \"sage_best_model.pt\")))\n",
    "# augment_data_sage = augment_labels(data, model=sage_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subgraph Property Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_graph_properties(data, model=None, save_dir='output/graph_analysis', verbose=True):\n",
    "    \"\"\"\n",
    "    Analyzes subgraph properties for different node types (train/val/test/unknown) and labels.\n",
    "    \n",
    "    Args:\n",
    "        data (torch_geometric.data.Data): The graph data object\n",
    "        model (torch.nn.Module, optional): Model to predict unknown node labels\n",
    "        save_dir (str): Directory to save results and plots\n",
    "        verbose (bool): Whether to print detailed information\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing all computed metrics\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import networkx as nx\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    from torch_geometric.utils import to_networkx\n",
    "    import torch.nn.functional as F\n",
    "    \n",
    "    # Create output directory\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Convert to NetworkX graph for analysis\n",
    "    G = to_networkx(data, to_undirected=True)\n",
    "    \n",
    "    # Define mask names for clear labeling\n",
    "    mask_names = {\n",
    "        'train': data.train_mask,\n",
    "        'val': data.val_mask,\n",
    "        'test': data.test_mask,\n",
    "        'unknown': data.y == 2\n",
    "    }\n",
    "    \n",
    "    # Define label names\n",
    "    label_names = {\n",
    "        0: 'licit',\n",
    "        1: 'illicit',\n",
    "        2: 'unknown'\n",
    "    }\n",
    "    \n",
    "    # Process unknown nodes if model is provided\n",
    "    if model is not None:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            out = model(data)\n",
    "            pred_probs = F.softmax(out, dim=1)\n",
    "            pred_labels = pred_probs.argmax(dim=1)\n",
    "            \n",
    "            # Create predicted label mask\n",
    "            pred_unknown_licit = (data.y == 2) & (pred_labels == 0)\n",
    "            pred_unknown_illicit = (data.y == 2) & (pred_labels == 1)\n",
    "            \n",
    "            # Add to masks dictionary\n",
    "            mask_names['pred_unknown_licit'] = pred_unknown_licit\n",
    "            mask_names['pred_unknown_illicit'] = pred_unknown_illicit\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"Unknown nodes predicted as licit: {pred_unknown_licit.sum().item()}\")\n",
    "                print(f\"Unknown nodes predicted as illicit: {pred_unknown_illicit.sum().item()}\")\n",
    "    \n",
    "    # Calculate graph-level metrics for each mask and label combination\n",
    "    metrics = {}\n",
    "    node_metrics = []\n",
    "    \n",
    "    # Calculate degree centrality for all nodes first (to avoid recalculation)\n",
    "    degree_centrality = nx.degree_centrality(G)\n",
    "    betweenness_centrality = nx.betweenness_centrality(G, k=min(100, len(G.nodes())), seed=42)\n",
    "    \n",
    "    try:\n",
    "        closeness_centrality = nx.closeness_centrality(G)\n",
    "    except:\n",
    "        if verbose:\n",
    "            print(\"Warning: Could not compute closeness centrality for the full graph (likely disconnected)\")\n",
    "        closeness_centrality = {node: 0 for node in G.nodes()}\n",
    "    \n",
    "    try:\n",
    "        eigenvector_centrality = nx.eigenvector_centrality(G, max_iter=1000)\n",
    "    except:\n",
    "        if verbose:\n",
    "            print(\"Warning: Eigenvector centrality did not converge, using approximate method\")\n",
    "        try:\n",
    "            eigenvector_centrality = nx.eigenvector_centrality_numpy(G)\n",
    "        except:\n",
    "            if verbose:\n",
    "                print(\"Warning: Could not compute eigenvector centrality, using zeros\")\n",
    "            eigenvector_centrality = {node: 0 for node in G.nodes()}\n",
    "            \n",
    "    clustering_coefficients = nx.clustering(G)\n",
    "    \n",
    "    # Start processing each mask type\n",
    "    for mask_name, mask in mask_names.items():\n",
    "        # Skip if no nodes in this mask\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "            \n",
    "        # Get node indices for this mask\n",
    "        node_indices = mask.nonzero(as_tuple=True)[0].cpu().numpy()\n",
    "        \n",
    "        # For train, val, test - further split by label\n",
    "        if mask_name in ['train', 'val', 'test']:\n",
    "            for label in [0, 1]:  # licit and illicit\n",
    "                label_mask = (data.y == label) & mask\n",
    "                label_indices = label_mask.nonzero(as_tuple=True)[0].cpu().numpy()\n",
    "                \n",
    "                if len(label_indices) == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Create label name for this group\n",
    "                group_name = f\"{mask_name}_{label_names[label]}\"\n",
    "                \n",
    "                # Process this subgroup\n",
    "                process_node_group(G, label_indices, group_name, metrics, node_metrics,\n",
    "                                 degree_centrality, betweenness_centrality, \n",
    "                                 closeness_centrality, eigenvector_centrality,\n",
    "                                 clustering_coefficients, verbose)\n",
    "        else:\n",
    "            # For unknown and predicted groups, process directly\n",
    "            process_node_group(G, node_indices, mask_name, metrics, node_metrics,\n",
    "                             degree_centrality, betweenness_centrality, \n",
    "                             closeness_centrality, eigenvector_centrality,\n",
    "                             clustering_coefficients, verbose)\n",
    "    \n",
    "    # Create a DataFrame with all node-level metrics\n",
    "    node_df = pd.DataFrame(node_metrics)\n",
    "    \n",
    "    # Save node-level metrics\n",
    "    node_df.to_csv(os.path.join(save_dir, 'node_metrics.csv'), index=False)\n",
    "    \n",
    "    # Save graph-level metrics\n",
    "    graph_metrics_df = pd.DataFrame.from_dict(metrics, orient='index')\n",
    "    graph_metrics_df.to_csv(os.path.join(save_dir, 'graph_metrics.csv'))\n",
    "    \n",
    "    # Create visualizations\n",
    "    create_visualizations(metrics, node_df, save_dir)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Analysis complete. Results saved to {save_dir}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def process_node_group(G, node_indices, group_name, metrics, node_metrics,\n",
    "                     degree_centrality, betweenness_centrality, \n",
    "                     closeness_centrality, eigenvector_centrality,\n",
    "                     clustering_coefficients, verbose):\n",
    "    \"\"\"Helper function to process a group of nodes and calculate metrics\"\"\"\n",
    "    \n",
    "    # Extract the subgraph\n",
    "    subgraph = G.subgraph(node_indices)\n",
    "    \n",
    "    # Calculate graph-level metrics\n",
    "    group_metrics = {\n",
    "        'num_nodes': len(subgraph),\n",
    "        'num_edges': subgraph.number_of_edges(),\n",
    "        'density': nx.density(subgraph),\n",
    "        'avg_degree': np.mean([d for _, d in subgraph.degree()]) if len(subgraph) > 0 else 0,\n",
    "        'avg_clustering': np.mean([clustering_coefficients.get(node, 0) for node in subgraph.nodes()]),\n",
    "    }\n",
    "    \n",
    "    # Calculate connected components\n",
    "    connected_components = list(nx.connected_components(subgraph))\n",
    "    group_metrics['num_components'] = len(connected_components)\n",
    "    \n",
    "    if len(connected_components) > 0:\n",
    "        largest_cc_size = max([len(cc) for cc in connected_components])\n",
    "        group_metrics['largest_component_size'] = largest_cc_size\n",
    "        group_metrics['largest_component_ratio'] = largest_cc_size / len(subgraph) if len(subgraph) > 0 else 0\n",
    "    else:\n",
    "        group_metrics['largest_component_size'] = 0\n",
    "        group_metrics['largest_component_ratio'] = 0\n",
    "    \n",
    "    # Calculate centrality averages\n",
    "    group_metrics['avg_degree_centrality'] = np.mean([degree_centrality.get(node, 0) for node in subgraph.nodes()])\n",
    "    group_metrics['avg_betweenness_centrality'] = np.mean([betweenness_centrality.get(node, 0) for node in subgraph.nodes()])\n",
    "    group_metrics['avg_closeness_centrality'] = np.mean([closeness_centrality.get(node, 0) for node in subgraph.nodes()])\n",
    "    group_metrics['avg_eigenvector_centrality'] = np.mean([eigenvector_centrality.get(node, 0) for node in subgraph.nodes()])\n",
    "    \n",
    "    # Add homophily measure - how many edges connect to same-group nodes\n",
    "    internal_edges = 0\n",
    "    external_edges = 0\n",
    "    \n",
    "    node_set = set(node_indices)\n",
    "    for node in subgraph:\n",
    "        for neighbor in G.neighbors(node):\n",
    "            if neighbor in node_set:\n",
    "                internal_edges += 1\n",
    "            else:\n",
    "                external_edges += 1\n",
    "    \n",
    "    # Each internal edge is counted twice (once from each end)\n",
    "    internal_edges = internal_edges / 2\n",
    "    group_metrics['internal_edges'] = internal_edges\n",
    "    group_metrics['external_edges'] = external_edges\n",
    "    group_metrics['homophily'] = internal_edges / (internal_edges + external_edges) if (internal_edges + external_edges) > 0 else 0\n",
    "    \n",
    "    # Store the metrics for this group\n",
    "    metrics[group_name] = group_metrics\n",
    "    \n",
    "    # Also store node-level metrics for later visualization\n",
    "    for node in subgraph.nodes():\n",
    "        node_metrics.append({\n",
    "            'node_id': node,\n",
    "            'group': group_name,\n",
    "            'degree': G.degree(node),\n",
    "            'degree_centrality': degree_centrality.get(node, 0),\n",
    "            'betweenness_centrality': betweenness_centrality.get(node, 0),\n",
    "            'closeness_centrality': closeness_centrality.get(node, 0),\n",
    "            'eigenvector_centrality': eigenvector_centrality.get(node, 0),\n",
    "            'clustering_coefficient': clustering_coefficients.get(node, 0)\n",
    "        })\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Processed {group_name}: {len(subgraph)} nodes, {subgraph.number_of_edges()} edges\")\n",
    "\n",
    "def create_visualizations(metrics, node_df, save_dir):\n",
    "    \"\"\"Create and save visualizations of the graph metrics\"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    \n",
    "    # Set the style\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    \n",
    "    # Convert metrics to DataFrame for easier plotting\n",
    "    metrics_df = pd.DataFrame.from_dict(metrics, orient='index')\n",
    "    \n",
    "    # 1. Centrality comparison between groups\n",
    "    centrality_metrics = ['avg_degree_centrality', 'avg_betweenness_centrality', \n",
    "                          'avg_closeness_centrality', 'avg_eigenvector_centrality']\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    metrics_df[centrality_metrics].plot(kind='bar', figsize=(15, 6))\n",
    "    plt.title('Average Centrality Metrics by Group')\n",
    "    plt.ylabel('Centrality Value')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, 'centrality_by_group.png'), dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Homophily and connectivity\n",
    "    connectivity_metrics = ['density', 'homophily', 'avg_clustering', 'largest_component_ratio']\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    metrics_df[connectivity_metrics].plot(kind='bar', figsize=(15, 6))\n",
    "    plt.title('Connectivity Metrics by Group')\n",
    "    plt.ylabel('Value')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, 'connectivity_by_group.png'), dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. Node and edge count\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    ax = metrics_df[['num_nodes', 'num_edges']].plot(kind='bar', figsize=(15, 6))\n",
    "    plt.title('Node and Edge Count by Group')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for container in ax.containers:\n",
    "        ax.bar_label(container, fmt='%.0f')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, 'node_edge_count.png'), dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # 4. Scatter plot of centrality metrics for nodes\n",
    "    centrality_pairs = [\n",
    "        ('degree_centrality', 'betweenness_centrality'),\n",
    "        ('degree_centrality', 'eigenvector_centrality'),\n",
    "        ('closeness_centrality', 'eigenvector_centrality')\n",
    "    ]\n",
    "    \n",
    "    # Define a color map for consistent group coloring\n",
    "    group_order = node_df['group'].unique()\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(group_order)))\n",
    "    group_colors = {group: colors[i] for i, group in enumerate(group_order)}\n",
    "    \n",
    "    for x_metric, y_metric in centrality_pairs:\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        \n",
    "        for group in group_order:\n",
    "            group_data = node_df[node_df['group'] == group]\n",
    "            plt.scatter(\n",
    "                group_data[x_metric], \n",
    "                group_data[y_metric],\n",
    "                alpha=0.6, \n",
    "                label=group,\n",
    "                color=group_colors[group],\n",
    "                s=50\n",
    "            )\n",
    "        \n",
    "        plt.title(f'{y_metric.replace(\"_\", \" \").title()} vs {x_metric.replace(\"_\", \" \").title()}')\n",
    "        plt.xlabel(x_metric.replace(\"_\", \" \").title())\n",
    "        plt.ylabel(y_metric.replace(\"_\", \" \").title())\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(save_dir, f'scatter_{x_metric}_vs_{y_metric}.png'), dpi=300)\n",
    "        plt.close()\n",
    "    \n",
    "    # 5. Distribution of degree centrality by group\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for group in group_order:\n",
    "        group_data = node_df[node_df['group'] == group]\n",
    "        sns.kdeplot(group_data['degree_centrality'], label=group)\n",
    "    \n",
    "    plt.title('Distribution of Degree Centrality by Group')\n",
    "    plt.xlabel('Degree Centrality')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, 'degree_centrality_distribution.png'), dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # 6. Heatmap of metrics correlation\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    correlation = metrics_df.corr()\n",
    "    mask = np.triu(np.ones_like(correlation, dtype=bool))\n",
    "    sns.heatmap(correlation, mask=mask, annot=True, cmap='coolwarm', vmin=-1, vmax=1, center=0)\n",
    "    plt.title('Correlation Between Graph Metrics')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, 'metrics_correlation.png'), dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Analysis with original data\n",
    "# original_metrics = analyze_graph_properties(\n",
    "#     data, \n",
    "#     save_dir='output/graph_analysis/original',\n",
    "#     verbose=True\n",
    "# )\n",
    "\n",
    "# # Analysis with model predictions\n",
    "# sage_metrics = analyze_graph_properties(\n",
    "#     data,\n",
    "#     model=sage_model,  # Using SAGE model for predictions\n",
    "#     save_dir='output/graph_analysis/model_predictions',\n",
    "#     verbose=True\n",
    "# )\n",
    "\n",
    "# Compare metrics between original and predicted\n",
    "def compare_metrics(original_metrics, predicted_metrics, save_path='output/graph_analysis/metrics_comparison.csv'):\n",
    "    \"\"\"Compare metrics between original and predicted data\"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Create DataFrames\n",
    "    original_df = pd.DataFrame.from_dict(original_metrics, orient='index')\n",
    "    predicted_df = pd.DataFrame.from_dict(predicted_metrics, orient='index')\n",
    "    \n",
    "    # Common groups (like train_licit, train_illicit, etc.)\n",
    "    common_groups = set(original_df.index).intersection(set(predicted_df.index))\n",
    "    \n",
    "    # Compare metrics for common groups\n",
    "    comparison = {}\n",
    "    for group in common_groups:\n",
    "        group_comparison = {}\n",
    "        for metric in original_df.columns:\n",
    "            original_value = original_df.loc[group, metric]\n",
    "            predicted_value = predicted_df.loc[group, metric]\n",
    "            difference = predicted_value - original_value\n",
    "            percent_change = (difference / original_value) * 100 if original_value != 0 else float('inf')\n",
    "            \n",
    "            group_comparison[f\"{metric}_original\"] = original_value\n",
    "            group_comparison[f\"{metric}_predicted\"] = predicted_value\n",
    "            group_comparison[f\"{metric}_diff\"] = difference\n",
    "            group_comparison[f\"{metric}_pct_change\"] = percent_change\n",
    "            \n",
    "        comparison[group] = group_comparison\n",
    "    \n",
    "    # Convert to DataFrame and save\n",
    "    comparison_df = pd.DataFrame.from_dict(comparison, orient='index')\n",
    "    comparison_df.to_csv(save_path)\n",
    "    \n",
    "    print(f\"Metrics comparison saved to {save_path}\")\n",
    "    return comparison_df\n",
    "\n",
    "# # Execute comparison\n",
    "# comparison = compare_metrics(original_metrics, sage_metrics)\n",
    "\n",
    "# # Print key findings\n",
    "# print(\"\\n==== KEY FINDINGS ====\")\n",
    "# print(\"Top metrics differences between original and predicted data:\")\n",
    "\n",
    "# # Find top 5 metrics with largest percent changes\n",
    "# for group in comparison.index:\n",
    "#     pct_change_cols = [col for col in comparison.columns if col.endswith('_pct_change')]\n",
    "#     largest_changes = comparison.loc[group, pct_change_cols].abs().nlargest(5)\n",
    "    \n",
    "#     print(f\"\\nGroup: {group}\")\n",
    "#     for metric in largest_changes.index:\n",
    "#         base_metric = metric.replace('_pct_change', '')\n",
    "#         original = comparison.loc[group, f\"{base_metric}_original\"]\n",
    "#         predicted = comparison.loc[group, f\"{base_metric}_predicted\"]\n",
    "#         pct_change = comparison.loc[group, metric]\n",
    "        \n",
    "#         change_direction = \"increased\" if pct_change > 0 else \"decreased\"\n",
    "#         print(f\"  {base_metric}: {original:.4f}  {predicted:.4f} ({change_direction} by {abs(pct_change):.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprehensive_graph_analysis(\n",
    "    data, \n",
    "    output_dir='output/comprehensive_analysis',\n",
    "    model_configs=None,\n",
    "    augment_percentage=0.3,\n",
    "    epochs=100,\n",
    "    random_seed=42,\n",
    "    verbose=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Performs comprehensive analysis of graph augmentation methods.\n",
    "    \n",
    "    Args:\n",
    "        data (torch_geometric.data.Data): The input graph data\n",
    "        output_dir (str): Root directory for saving results\n",
    "        model_configs (dict, optional): Model configurations\n",
    "        augment_percentage (float): Percentage of unknown nodes to add (default: 0.3)\n",
    "        epochs (int): Number of training epochs\n",
    "        random_seed (int): Random seed for reproducibility\n",
    "        verbose (bool): Whether to print detailed information\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing all results and comparisons\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import time\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    from datetime import datetime\n",
    "    \n",
    "    # Set random seeds\n",
    "    set_seed_for_torch(random_seed)\n",
    "    set_seed_for_numpy(random_seed)\n",
    "    set_seed_for_random(random_seed)\n",
    "    \n",
    "    # Create output directory\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_dir = f\"{output_dir}_{timestamp}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Setup default model configurations if not provided\n",
    "    if model_configs is None:\n",
    "        model_configs = {\n",
    "            'input_dim': data.x.shape[1],\n",
    "            'hidden_dim': 64,\n",
    "            'output_dim': len(torch.unique(data.y[data.y != 2])),\n",
    "            'gat_heads': 8\n",
    "        }\n",
    "    \n",
    "    # Create subdirectories\n",
    "    original_dir = os.path.join(output_dir, \"original\")\n",
    "    models_dir = os.path.join(output_dir, \"models\")\n",
    "    augmented_dir = os.path.join(output_dir, \"augmented\")\n",
    "    comparison_dir = os.path.join(output_dir, \"comparison\")\n",
    "    \n",
    "    for directory in [original_dir, models_dir, augmented_dir, comparison_dir]:\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "    \n",
    "    # Dictionary to store all results\n",
    "    results = {\n",
    "        'original': {},\n",
    "        'base_models': {},\n",
    "        'augmented': {},\n",
    "        'augmented_models': {},\n",
    "        'comparison': {}\n",
    "    }\n",
    "    \n",
    "    # Step 1: Analyze original graph properties\n",
    "    if verbose:\n",
    "        print(\"\\n==== Step 1: Analyzing Original Graph Properties ====\")\n",
    "    \n",
    "    original_metrics = analyze_graph_properties(\n",
    "        data, \n",
    "        save_dir=os.path.join(original_dir, \"graph_properties\"),\n",
    "        verbose=verbose\n",
    "    )\n",
    "    results['original']['metrics'] = original_metrics\n",
    "    \n",
    "    # Step 2: Train GAT and GraphSAGE on known graph\n",
    "    if verbose:\n",
    "        print(\"\\n==== Step 2: Training Base Models ====\")\n",
    "    \n",
    "    # For GAT model\n",
    "    gat_args = {\n",
    "        'model_name': 'GAT',\n",
    "        'input_dim': model_configs['input_dim'],\n",
    "        'hidden_dim': model_configs['hidden_dim'],\n",
    "        'output_dim': model_configs['output_dim'],\n",
    "        'heads': model_configs['gat_heads']\n",
    "    }\n",
    "    \n",
    "    gat_path = os.path.join(models_dir, \"base_gat\")\n",
    "    os.makedirs(gat_path, exist_ok=True)\n",
    "    \n",
    "    base_gat_results = train_gnn_model(\n",
    "        graph_data=data,\n",
    "        checkpoint_path=os.path.join(gat_path, \"base_gat_model.pt\"),\n",
    "        model_args=gat_args,\n",
    "        num_epochs=epochs,\n",
    "        verbose=verbose\n",
    "    )\n",
    "    \n",
    "    # For GraphSAGE model\n",
    "    sage_args = {\n",
    "        'model_name': 'GraphSAGE',\n",
    "        'input_dim': model_configs['input_dim'],\n",
    "        'hidden_dim': model_configs['hidden_dim'],\n",
    "        'output_dim': model_configs['output_dim']\n",
    "    }\n",
    "    \n",
    "    sage_path = os.path.join(models_dir, \"base_sage\")\n",
    "    os.makedirs(sage_path, exist_ok=True)\n",
    "    \n",
    "    base_sage_results = train_gnn_model(\n",
    "        graph_data=data,\n",
    "        checkpoint_path=os.path.join(sage_path, \"base_sage_model.pt\"),\n",
    "        model_args=sage_args,\n",
    "        num_epochs=epochs,\n",
    "        verbose=verbose\n",
    "    )\n",
    "    \n",
    "    # Step 3: Inspect results and analyze model properties\n",
    "    if verbose:\n",
    "        print(\"\\n==== Step 3: Inspecting Base Model Results ====\")\n",
    "        \n",
    "    gat_metrics = inspect_model_results(base_gat_results, save_dir=gat_path, model_name=\"base_gat\")\n",
    "    sage_metrics = inspect_model_results(base_sage_results, save_dir=sage_path, model_name=\"base_sage\")\n",
    "    \n",
    "    results['base_models']['gat'] = {\n",
    "        'model': base_gat_results['model'],\n",
    "        'metrics': gat_metrics,\n",
    "        'training_history': base_gat_results['training_history']\n",
    "    }\n",
    "    \n",
    "    results['base_models']['sage'] = {\n",
    "        'model': base_sage_results['model'],\n",
    "        'metrics': sage_metrics,\n",
    "        'training_history': base_sage_results['training_history']\n",
    "    }\n",
    "    \n",
    "    # Analyze graph properties with base models\n",
    "    gat_model = base_gat_results['model']\n",
    "    sage_model = base_sage_results['model']\n",
    "    \n",
    "    gat_graph_metrics = analyze_graph_properties(\n",
    "        data, \n",
    "        model=gat_model,\n",
    "        save_dir=os.path.join(gat_path, \"graph_properties\"),\n",
    "        verbose=verbose\n",
    "    )\n",
    "    \n",
    "    sage_graph_metrics = analyze_graph_properties(\n",
    "        data, \n",
    "        model=sage_model,\n",
    "        save_dir=os.path.join(sage_path, \"graph_properties\"),\n",
    "        verbose=verbose\n",
    "    )\n",
    "    \n",
    "    results['base_models']['gat']['graph_metrics'] = gat_graph_metrics\n",
    "    results['base_models']['sage']['graph_metrics'] = sage_graph_metrics\n",
    "    \n",
    "    # Step 4: Augment data using different methods\n",
    "    if verbose:\n",
    "        print(\"\\n==== Step 4: Augmenting Data with Different Methods ====\")\n",
    "    \n",
    "    # Method 1: Label propagation (default method)\n",
    "    lp_augmented_data = augment_labels(data, percentage=augment_percentage)\n",
    "    \n",
    "    # Method 2: GAT-based augmentation\n",
    "    gat_augmented_data = augment_labels(data, percentage=augment_percentage, model=gat_model)\n",
    "    \n",
    "    # Method 3: GraphSAGE-based augmentation\n",
    "    sage_augmented_data = augment_labels(data, percentage=augment_percentage, model=sage_model)\n",
    "    \n",
    "    # Store augmented data\n",
    "    augmented_data = {\n",
    "        'label_propagation': lp_augmented_data,\n",
    "        'gat': gat_augmented_data,\n",
    "        'sage': sage_augmented_data\n",
    "    }\n",
    "    results['augmented']['data'] = augmented_data\n",
    "    \n",
    "    # Step 5: Analyze graph properties for each augmented method\n",
    "    if verbose:\n",
    "        print(\"\\n==== Step 5: Analyzing Augmented Graph Properties ====\")\n",
    "    \n",
    "    for method_name, aug_data in augmented_data.items():\n",
    "        method_dir = os.path.join(augmented_dir, method_name)\n",
    "        os.makedirs(method_dir, exist_ok=True)\n",
    "        \n",
    "        # Analyze without model predictions\n",
    "        aug_metrics = analyze_graph_properties(\n",
    "            aug_data, \n",
    "            save_dir=os.path.join(method_dir, \"graph_properties\"),\n",
    "            verbose=verbose\n",
    "        )\n",
    "        \n",
    "        results['augmented'][f'{method_name}_metrics'] = aug_metrics\n",
    "    \n",
    "    # Step 6: Train models on augmented graphs\n",
    "    if verbose:\n",
    "        print(\"\\n==== Step 6: Training Models on Augmented Graphs ====\")\n",
    "    \n",
    "    augmented_models = {}\n",
    "    \n",
    "    for method_name, aug_data in augmented_data.items():\n",
    "        method_dir = os.path.join(augmented_dir, method_name)\n",
    "        \n",
    "        # Train GAT on augmented data\n",
    "        gat_aug_path = os.path.join(method_dir, \"gat\")\n",
    "        os.makedirs(gat_aug_path, exist_ok=True)\n",
    "        \n",
    "        gat_aug_results = train_gnn_model(\n",
    "            graph_data=aug_data,\n",
    "            checkpoint_path=os.path.join(gat_aug_path, f\"{method_name}_gat_model.pt\"),\n",
    "            model_args=gat_args,\n",
    "            num_epochs=epochs,\n",
    "            verbose=verbose\n",
    "        )\n",
    "        \n",
    "        # Train GraphSAGE on augmented data\n",
    "        sage_aug_path = os.path.join(method_dir, \"sage\")\n",
    "        os.makedirs(sage_aug_path, exist_ok=True)\n",
    "        \n",
    "        sage_aug_results = train_gnn_model(\n",
    "            graph_data=aug_data,\n",
    "            checkpoint_path=os.path.join(sage_aug_path, f\"{method_name}_sage_model.pt\"),\n",
    "            model_args=sage_args,\n",
    "            num_epochs=epochs,\n",
    "            verbose=verbose\n",
    "        )\n",
    "        \n",
    "        # Inspect model results\n",
    "        gat_aug_metrics = inspect_model_results(\n",
    "            gat_aug_results, \n",
    "            save_dir=gat_aug_path, \n",
    "            model_name=f\"{method_name}_gat\"\n",
    "        )\n",
    "        \n",
    "        sage_aug_metrics = inspect_model_results(\n",
    "            sage_aug_results, \n",
    "            save_dir=sage_aug_path, \n",
    "            model_name=f\"{method_name}_sage\"\n",
    "        )\n",
    "        \n",
    "        # Store model results\n",
    "        augmented_models[f'{method_name}_gat'] = {\n",
    "            'model': gat_aug_results['model'],\n",
    "            'metrics': gat_aug_metrics,\n",
    "            'training_history': gat_aug_results['training_history']\n",
    "        }\n",
    "        \n",
    "        augmented_models[f'{method_name}_sage'] = {\n",
    "            'model': sage_aug_results['model'],\n",
    "            'metrics': sage_aug_metrics,\n",
    "            'training_history': sage_aug_results['training_history']\n",
    "        }\n",
    "    \n",
    "    results['augmented_models'] = augmented_models\n",
    "    \n",
    "    # Step 7: Analyze graph properties using augmented models\n",
    "    if verbose:\n",
    "        print(\"\\n==== Step 7: Analyzing Graph Properties with Augmented Models ====\")\n",
    "    \n",
    "    for model_name, model_info in augmented_models.items():\n",
    "        model = model_info['model']\n",
    "        method_name = model_name.split('_')[0]\n",
    "        model_type = model_name.split('_')[1]\n",
    "        \n",
    "        save_dir = os.path.join(augmented_dir, method_name, model_type, \"graph_properties_with_model\")\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        # Analyze graph properties using this model\n",
    "        graph_metrics = analyze_graph_properties(\n",
    "            data,  # Use original data to see how model predicts\n",
    "            model=model,\n",
    "            save_dir=save_dir,\n",
    "            verbose=verbose\n",
    "        )\n",
    "        \n",
    "        results['augmented_models'][model_name]['graph_metrics'] = graph_metrics\n",
    "    \n",
    "    # Step 8: Save important metrics\n",
    "    if verbose:\n",
    "        print(\"\\n==== Step 8: Saving Important Metrics ====\")\n",
    "    \n",
    "    # Compile accuracy metrics for all models\n",
    "    accuracy_metrics = {\n",
    "        'base_gat': results['base_models']['gat']['metrics'],\n",
    "        'base_sage': results['base_models']['sage']['metrics']\n",
    "    }\n",
    "    \n",
    "    for model_name in augmented_models.keys():\n",
    "        accuracy_metrics[model_name] = augmented_models[model_name]['metrics']\n",
    "    \n",
    "    # Convert to DataFrame and save\n",
    "    accuracy_df = pd.DataFrame.from_dict(accuracy_metrics, orient='index')\n",
    "    accuracy_df.to_csv(os.path.join(comparison_dir, \"model_accuracy_comparison.csv\"))\n",
    "    \n",
    "    # Step 9: Create comprehensive comparison results\n",
    "    if verbose:\n",
    "        print(\"\\n==== Step 9: Creating Comprehensive Comparison ====\")\n",
    "    \n",
    "    # 1. Compare test accuracy across all models\n",
    "    test_accuracies = {}\n",
    "    for model_name, metrics in accuracy_metrics.items():\n",
    "        if isinstance(metrics, dict) and 'Test Accuracy' in metrics:\n",
    "            test_accuracies[model_name] = float(metrics['Test Accuracy'])\n",
    "    \n",
    "    # Create and save accuracy comparison plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    models = list(test_accuracies.keys())\n",
    "    accuracies = [test_accuracies[model] for model in models]\n",
    "    \n",
    "    # Use different colors for base models vs augmented models\n",
    "    colors = ['blue' if 'base' in model else 'green' for model in models]\n",
    "    \n",
    "    bars = plt.bar(models, accuracies, color=colors)\n",
    "    plt.title('Test Accuracy Comparison Across Models')\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('Test Accuracy')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
    "                f'{height:.4f}', ha='center', va='bottom', rotation=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(comparison_dir, 'test_accuracy_comparison.png'), dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Compare graph property consistency\n",
    "    \n",
    "    # Collect all graph metrics\n",
    "    all_graph_metrics = {\n",
    "        'original': results['original']['metrics'],\n",
    "        'base_gat': results['base_models']['gat']['graph_metrics'],\n",
    "        'base_sage': results['base_models']['sage']['graph_metrics']\n",
    "    }\n",
    "    \n",
    "    for model_name, model_info in augmented_models.items():\n",
    "        if 'graph_metrics' in model_info:\n",
    "            all_graph_metrics[model_name] = model_info['graph_metrics']\n",
    "    \n",
    "    # Calculate similarity scores between original and predicted metrics\n",
    "    similarity_scores = {}\n",
    "    \n",
    "    for model_name, metrics in all_graph_metrics.items():\n",
    "        if model_name == 'original':\n",
    "            continue\n",
    "            \n",
    "        # Compare with original metrics\n",
    "        similarity = calculate_metrics_similarity(\n",
    "            all_graph_metrics['original'], \n",
    "            metrics,\n",
    "            save_path=os.path.join(comparison_dir, f\"{model_name}_vs_original_similarity.csv\")\n",
    "        )\n",
    "        \n",
    "        similarity_scores[model_name] = similarity\n",
    "    \n",
    "    # Create and save similarity comparison plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    models = list(similarity_scores.keys())\n",
    "    scores = [similarity_scores[model]['overall_similarity'] for model in models]\n",
    "    \n",
    "    # Use different colors for base models vs augmented models\n",
    "    colors = ['blue' if 'base' in model else 'green' for model in models]\n",
    "    \n",
    "    bars = plt.bar(models, scores, color=colors)\n",
    "    plt.title('Graph Property Consistency Scores')\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('Similarity Score (higher is better)')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                f'{height:.4f}', ha='center', va='bottom', rotation=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(comparison_dir, 'graph_property_similarity.png'), dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. Create summary table with key metrics\n",
    "    summary_metrics = []\n",
    "    \n",
    "    # Base models\n",
    "    summary_metrics.append({\n",
    "        'model': 'base_gat',\n",
    "        'test_accuracy': float(results['base_models']['gat']['metrics']['Test Accuracy']),\n",
    "        'training_time': float(results['base_models']['gat']['metrics']['Training Time (s)']),\n",
    "        'consistency_score': similarity_scores['base_gat']['overall_similarity'] if 'base_gat' in similarity_scores else 0\n",
    "    })\n",
    "    \n",
    "    summary_metrics.append({\n",
    "        'model': 'base_sage',\n",
    "        'test_accuracy': float(results['base_models']['sage']['metrics']['Test Accuracy']),\n",
    "        'training_time': float(results['base_models']['sage']['metrics']['Training Time (s)']),\n",
    "        'consistency_score': similarity_scores['base_sage']['overall_similarity'] if 'base_sage' in similarity_scores else 0\n",
    "    })\n",
    "    \n",
    "    # Augmented models\n",
    "    for model_name, model_info in augmented_models.items():\n",
    "        summary_metrics.append({\n",
    "            'model': model_name,\n",
    "            'test_accuracy': float(model_info['metrics']['Test Accuracy']),\n",
    "            'training_time': float(model_info['metrics']['Training Time (s)']),\n",
    "            'consistency_score': similarity_scores[model_name]['overall_similarity'] if model_name in similarity_scores else 0\n",
    "        })\n",
    "    \n",
    "    # Create DataFrame and save\n",
    "    summary_df = pd.DataFrame(summary_metrics)\n",
    "    summary_df.to_csv(os.path.join(comparison_dir, 'summary_metrics.csv'), index=False)\n",
    "    \n",
    "    # 4. Find the best model based on combined metrics\n",
    "    summary_df['combined_score'] = (\n",
    "        summary_df['test_accuracy'] * 0.6 +  # Weight accuracy more\n",
    "        summary_df['consistency_score'] * 0.4  # Weight consistency less\n",
    "    )\n",
    "    \n",
    "    best_model = summary_df.sort_values('combined_score', ascending=False).iloc[0]\n",
    "    \n",
    "    # Print and save conclusion\n",
    "    conclusion = f\"\"\"\n",
    "    ===== ANALYSIS CONCLUSION =====\n",
    "    \n",
    "    Best Overall Model: {best_model['model']}\n",
    "    Test Accuracy: {best_model['test_accuracy']:.4f}\n",
    "    Graph Consistency Score: {best_model['consistency_score']:.4f}\n",
    "    Combined Score: {best_model['combined_score']:.4f}\n",
    "    Training Time: {best_model['training_time']:.2f} seconds\n",
    "    \n",
    "    Key Findings:\n",
    "    - The best model for test accuracy was: {summary_df.loc[summary_df['test_accuracy'].idxmax(), 'model']} ({summary_df['test_accuracy'].max():.4f})\n",
    "    - The best model for graph consistency was: {summary_df.loc[summary_df['consistency_score'].idxmax(), 'model']} ({summary_df['consistency_score'].max():.4f})\n",
    "    - The fastest model was: {summary_df.loc[summary_df['training_time'].idxmin(), 'model']} ({summary_df['training_time'].min():.2f} seconds)\n",
    "    \n",
    "    Recommendation:\n",
    "    The {best_model['model']} model provides the best balance between prediction accuracy and graph structure preservation.\n",
    "    \"\"\"\n",
    "    \n",
    "    if verbose:\n",
    "        print(conclusion)\n",
    "    \n",
    "    # Save conclusion\n",
    "    with open(os.path.join(comparison_dir, 'conclusion.txt'), 'w') as f:\n",
    "        f.write(conclusion)\n",
    "    \n",
    "    # Save overall results dictionary (without model objects which aren't serializable)\n",
    "    serializable_results = {}\n",
    "    for key, value in results.items():\n",
    "        if key in ['original', 'comparison']:\n",
    "            serializable_results[key] = value\n",
    "        else:\n",
    "            serializable_results[key] = {}\n",
    "            for subkey, subvalue in value.items():\n",
    "                if isinstance(subvalue, dict) and 'model' in subvalue:\n",
    "                    serializable_results[key][subkey] = {k: v for k, v in subvalue.items() if k != 'model'}\n",
    "                else:\n",
    "                    serializable_results[key][subkey] = subvalue\n",
    "    \n",
    "    # Save as pickle if comprehensive results are needed\n",
    "    import pickle\n",
    "    with open(os.path.join(output_dir, 'serializable_results.pkl'), 'wb') as f:\n",
    "        pickle.dump(serializable_results, f)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def calculate_metrics_similarity(original_metrics, predicted_metrics, \n",
    "                               save_path=None, key_metrics=None):\n",
    "    \"\"\"\n",
    "    Calculate similarity/consistency between original and predicted graph metrics.\n",
    "    \n",
    "    Args:\n",
    "        original_metrics (dict): Original graph metrics\n",
    "        predicted_metrics (dict): Predicted graph metrics\n",
    "        save_path (str, optional): Path to save the comparison\n",
    "        key_metrics (list, optional): List of key metrics to prioritize\n",
    "        \n",
    "    Returns:\n",
    "        dict: Similarity scores\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    # Define key metrics if not provided\n",
    "    if key_metrics is None:\n",
    "        key_metrics = [\n",
    "            'homophily', 'density', 'avg_clustering', 'avg_degree_centrality',\n",
    "            'avg_betweenness_centrality', 'largest_component_ratio'\n",
    "        ]\n",
    "    \n",
    "    # Common groups\n",
    "    common_groups = set(original_metrics.keys()).intersection(set(predicted_metrics.keys()))\n",
    "    \n",
    "    # Calculate similarity for each metric\n",
    "    similarity_scores = {}\n",
    "    all_scores = []\n",
    "    \n",
    "    for group in common_groups:\n",
    "        group_similarity = {}\n",
    "        group_scores = []\n",
    "        \n",
    "        # Check if group exists in both metrics\n",
    "        if group in original_metrics and group in predicted_metrics:\n",
    "            orig_group = original_metrics[group]\n",
    "            pred_group = predicted_metrics[group]\n",
    "            \n",
    "            # Find common metrics\n",
    "            common_metrics = set(orig_group.keys()).intersection(set(pred_group.keys()))\n",
    "            \n",
    "            for metric in common_metrics:\n",
    "                if metric in ['num_nodes', 'num_edges', 'num_components']:\n",
    "                    continue  # Skip count metrics\n",
    "                \n",
    "                orig_val = orig_group.get(metric, 0)\n",
    "                pred_val = pred_group.get(metric, 0)\n",
    "                \n",
    "                # Calculate similarity (1 - relative difference)\n",
    "                if orig_val != 0:\n",
    "                    rel_diff = abs(pred_val - orig_val) / abs(orig_val)\n",
    "                    similarity = max(0, 1 - min(rel_diff, 1))  # Cap at 0-1 range\n",
    "                else:\n",
    "                    # If original is 0, check if prediction is also close to 0\n",
    "                    similarity = 1 if abs(pred_val) < 0.01 else 0\n",
    "                \n",
    "                group_similarity[metric] = similarity\n",
    "                group_scores.append(similarity)\n",
    "                \n",
    "                # If this is a key metric, add it to the overall scores with higher weight\n",
    "                if metric in key_metrics:\n",
    "                    all_scores.append(similarity)\n",
    "                    all_scores.append(similarity)  # Add twice for more weight\n",
    "                else:\n",
    "                    all_scores.append(similarity)\n",
    "        \n",
    "        # Calculate group average\n",
    "        if group_scores:\n",
    "            group_similarity['average'] = np.mean(group_scores)\n",
    "            similarity_scores[group] = group_similarity\n",
    "    \n",
    "    # Calculate overall similarity\n",
    "    overall_similarity = np.mean(all_scores) if all_scores else 0\n",
    "    similarity_scores['overall_similarity'] = overall_similarity\n",
    "    \n",
    "    # Save comparison if path provided\n",
    "    if save_path:\n",
    "        comparison_data = []\n",
    "        \n",
    "        for group in common_groups:\n",
    "            if group in similarity_scores:\n",
    "                for metric, score in similarity_scores[group].items():\n",
    "                    if metric != 'average':\n",
    "                        comparison_data.append({\n",
    "                            'group': group,\n",
    "                            'metric': metric,\n",
    "                            'original_value': original_metrics[group].get(metric, np.nan),\n",
    "                            'predicted_value': predicted_metrics[group].get(metric, np.nan),\n",
    "                            'similarity_score': score\n",
    "                        })\n",
    "        \n",
    "        # Convert to DataFrame and save\n",
    "        df = pd.DataFrame(comparison_data)\n",
    "        df.to_csv(save_path, index=False)\n",
    "    \n",
    "    return similarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Step 1: Analyzing Original Graph Properties ====\n",
      "Processed train_licit: 3602 nodes, 651 edges\n",
      "Processed train_illicit: 33649 nodes, 21207 edges\n",
      "Processed val_licit: 508 nodes, 18 edges\n",
      "Processed val_illicit: 4148 nodes, 379 edges\n",
      "Processed test_licit: 435 nodes, 8 edges\n",
      "Processed test_illicit: 4222 nodes, 394 edges\n",
      "Processed unknown: 157205 nodes, 131778 edges\n",
      "Analysis complete. Results saved to output/comprehensive_analysis_20250410_171856/original/graph_properties\n",
      "\n",
      "==== Step 2: Training Base Models ====\n",
      "GAT Epoch: 010, Loss: 0.8470, Train Acc: 0.7809, Val Acc: 0.7788\n",
      "GAT Epoch: 020, Loss: 0.6171, Train Acc: 0.7802, Val Acc: 0.7801\n",
      "GAT Epoch: 030, Loss: 0.4966, Train Acc: 0.7180, Val Acc: 0.7118\n",
      "GAT Epoch: 040, Loss: 0.4165, Train Acc: 0.8239, Val Acc: 0.8232\n",
      "GAT Epoch: 050, Loss: 0.3771, Train Acc: 0.8344, Val Acc: 0.8344\n",
      "GAT Epoch: 060, Loss: 0.3567, Train Acc: 0.8602, Val Acc: 0.8582\n",
      "GAT Epoch: 070, Loss: 0.3427, Train Acc: 0.8573, Val Acc: 0.8567\n",
      "GAT Epoch: 080, Loss: 0.3331, Train Acc: 0.8895, Val Acc: 0.8819\n",
      "GAT Epoch: 090, Loss: 0.3228, Train Acc: 0.9001, Val Acc: 0.8967\n",
      "GAT Epoch: 100, Loss: 0.3116, Train Acc: 0.9023, Val Acc: 0.8978\n",
      "GAT Epoch: 110, Loss: 0.3078, Train Acc: 0.9228, Val Acc: 0.9180\n",
      "GAT Epoch: 120, Loss: 0.2999, Train Acc: 0.9108, Val Acc: 0.9066\n",
      "GAT Epoch: 130, Loss: 0.2946, Train Acc: 0.9235, Val Acc: 0.9162\n",
      "GAT Epoch: 140, Loss: 0.2911, Train Acc: 0.9219, Val Acc: 0.9175\n",
      "GAT Epoch: 150, Loss: 0.2880, Train Acc: 0.9192, Val Acc: 0.9089\n",
      "GAT Epoch: 160, Loss: 0.2866, Train Acc: 0.9261, Val Acc: 0.9186\n",
      "GAT Epoch: 170, Loss: 0.2796, Train Acc: 0.9251, Val Acc: 0.9180\n",
      "GAT Epoch: 180, Loss: 0.2775, Train Acc: 0.9158, Val Acc: 0.9049\n",
      "GAT Epoch: 190, Loss: 0.2774, Train Acc: 0.9181, Val Acc: 0.9070\n",
      "GAT Epoch: 200, Loss: 0.2723, Train Acc: 0.9179, Val Acc: 0.9068\n",
      "GAT Test Accuracy: 0.9216\n",
      "GAT Training Time: 426.71 seconds\n",
      "GraphSAGE Epoch: 010, Loss: 0.3861, Train Acc: 0.9041, Val Acc: 0.8937\n",
      "GraphSAGE Epoch: 020, Loss: 0.2166, Train Acc: 0.9226, Val Acc: 0.9162\n",
      "GraphSAGE Epoch: 030, Loss: 0.1981, Train Acc: 0.9372, Val Acc: 0.9338\n",
      "GraphSAGE Epoch: 040, Loss: 0.1716, Train Acc: 0.9386, Val Acc: 0.9334\n",
      "GraphSAGE Epoch: 050, Loss: 0.1588, Train Acc: 0.9495, Val Acc: 0.9450\n",
      "GraphSAGE Epoch: 060, Loss: 0.1452, Train Acc: 0.9590, Val Acc: 0.9555\n",
      "GraphSAGE Epoch: 070, Loss: 0.1368, Train Acc: 0.9652, Val Acc: 0.9641\n",
      "GraphSAGE Epoch: 080, Loss: 0.1253, Train Acc: 0.9677, Val Acc: 0.9663\n",
      "GraphSAGE Epoch: 090, Loss: 0.1232, Train Acc: 0.9694, Val Acc: 0.9701\n",
      "GraphSAGE Epoch: 100, Loss: 0.1161, Train Acc: 0.9710, Val Acc: 0.9708\n",
      "GraphSAGE Epoch: 110, Loss: 0.1121, Train Acc: 0.9720, Val Acc: 0.9712\n",
      "GraphSAGE Epoch: 120, Loss: 0.1095, Train Acc: 0.9730, Val Acc: 0.9725\n",
      "GraphSAGE Epoch: 130, Loss: 0.1044, Train Acc: 0.9741, Val Acc: 0.9736\n",
      "GraphSAGE Epoch: 140, Loss: 0.1024, Train Acc: 0.9750, Val Acc: 0.9751\n",
      "GraphSAGE Epoch: 150, Loss: 0.0995, Train Acc: 0.9758, Val Acc: 0.9753\n",
      "GraphSAGE Epoch: 160, Loss: 0.0971, Train Acc: 0.9765, Val Acc: 0.9757\n",
      "GraphSAGE Epoch: 170, Loss: 0.0948, Train Acc: 0.9769, Val Acc: 0.9766\n",
      "GraphSAGE Epoch: 180, Loss: 0.0935, Train Acc: 0.9773, Val Acc: 0.9768\n",
      "GraphSAGE Epoch: 190, Loss: 0.0903, Train Acc: 0.9777, Val Acc: 0.9768\n",
      "GraphSAGE Epoch: 200, Loss: 0.0904, Train Acc: 0.9779, Val Acc: 0.9766\n",
      "GraphSAGE Test Accuracy: 0.9740\n",
      "GraphSAGE Training Time: 76.91 seconds\n",
      "\n",
      "==== Step 3: Inspecting Base Model Results ====\n",
      "\n",
      "==================== base_gat Results ====================\n",
      "Model: base_gat\n",
      "Test Accuracy: 0.9216\n",
      "Validation Accuracy: 0.9212\n",
      "Training Time (s): 426.71\n",
      "Final Training Loss: 0.2723\n",
      "Number of Epochs: 200\n",
      "==================================================\n",
      "\n",
      "==================== base_sage Results ====================\n",
      "Model: base_sage\n",
      "Test Accuracy: 0.9740\n",
      "Validation Accuracy: 0.9770\n",
      "Training Time (s): 76.91\n",
      "Final Training Loss: 0.0904\n",
      "Number of Epochs: 200\n",
      "==================================================\n",
      "Unknown nodes predicted as licit: 2924\n",
      "Unknown nodes predicted as illicit: 154281\n",
      "Processed train_licit: 3602 nodes, 651 edges\n",
      "Processed train_illicit: 33649 nodes, 21207 edges\n",
      "Processed val_licit: 508 nodes, 18 edges\n",
      "Processed val_illicit: 4148 nodes, 379 edges\n",
      "Processed test_licit: 435 nodes, 8 edges\n",
      "Processed test_illicit: 4222 nodes, 394 edges\n",
      "Processed unknown: 157205 nodes, 131778 edges\n",
      "Processed pred_unknown_licit: 2924 nodes, 290 edges\n",
      "Processed pred_unknown_illicit: 154281 nodes, 129899 edges\n",
      "Analysis complete. Results saved to output/comprehensive_analysis_20250410_171856/models/base_gat/graph_properties\n",
      "Unknown nodes predicted as licit: 9835\n",
      "Unknown nodes predicted as illicit: 147370\n",
      "Processed train_licit: 3602 nodes, 651 edges\n",
      "Processed train_illicit: 33649 nodes, 21207 edges\n",
      "Processed val_licit: 508 nodes, 18 edges\n",
      "Processed val_illicit: 4148 nodes, 379 edges\n",
      "Processed test_licit: 435 nodes, 8 edges\n",
      "Processed test_illicit: 4222 nodes, 394 edges\n",
      "Processed unknown: 157205 nodes, 131778 edges\n",
      "Processed pred_unknown_licit: 9835 nodes, 1599 edges\n",
      "Processed pred_unknown_illicit: 147370 nodes, 120051 edges\n",
      "Analysis complete. Results saved to output/comprehensive_analysis_20250410_171856/models/base_sage/graph_properties\n",
      "\n",
      "==== Step 4: Augmenting Data with Different Methods ====\n",
      "Using self-supervised learning for label augmentation\n",
      "Added 47161 previously unknown nodes to training set:\n",
      "  - Predicted illicit: 45741 (96.99%)\n",
      "  - Predicted licit: 1420 (3.01%)\n",
      "Using provided model for label augmentation\n",
      "Added 47161 previously unknown nodes to training set:\n",
      "  - Predicted illicit: 47130 (99.93%)\n",
      "  - Predicted licit: 31 (0.07%)\n",
      "Using provided model for label augmentation\n",
      "Added 47161 previously unknown nodes to training set:\n",
      "  - Predicted illicit: 47135 (99.94%)\n",
      "  - Predicted licit: 26 (0.06%)\n",
      "\n",
      "==== Step 5: Analyzing Augmented Graph Properties ====\n",
      "Processed train_licit: 5022 nodes, 2172 edges\n",
      "Processed train_illicit: 79390 nodes, 77956 edges\n",
      "Processed val_licit: 508 nodes, 18 edges\n",
      "Processed val_illicit: 4148 nodes, 379 edges\n",
      "Processed test_licit: 435 nodes, 8 edges\n",
      "Processed test_illicit: 4222 nodes, 394 edges\n",
      "Processed unknown: 110044 nodes, 86291 edges\n",
      "Analysis complete. Results saved to output/comprehensive_analysis_20250410_171856/augmented/label_propagation/graph_properties\n",
      "Processed train_licit: 3633 nodes, 655 edges\n",
      "Processed train_illicit: 80779 nodes, 79305 edges\n",
      "Processed val_licit: 508 nodes, 18 edges\n",
      "Processed val_illicit: 4148 nodes, 379 edges\n",
      "Processed test_licit: 435 nodes, 8 edges\n",
      "Processed test_illicit: 4222 nodes, 394 edges\n",
      "Processed unknown: 110044 nodes, 82403 edges\n",
      "Analysis complete. Results saved to output/comprehensive_analysis_20250410_171856/augmented/gat/graph_properties\n",
      "Processed train_licit: 3628 nodes, 651 edges\n",
      "Processed train_illicit: 80784 nodes, 71659 edges\n",
      "Processed val_licit: 508 nodes, 18 edges\n",
      "Processed val_illicit: 4148 nodes, 379 edges\n",
      "Processed test_licit: 435 nodes, 8 edges\n",
      "Processed test_illicit: 4222 nodes, 394 edges\n",
      "Processed unknown: 110044 nodes, 73468 edges\n",
      "Analysis complete. Results saved to output/comprehensive_analysis_20250410_171856/augmented/sage/graph_properties\n",
      "\n",
      "==== Step 6: Training Models on Augmented Graphs ====\n",
      "GAT Epoch: 010, Loss: 1.0465, Train Acc: 0.9265, Val Acc: 0.8881\n",
      "GAT Epoch: 020, Loss: 0.7376, Train Acc: 0.5126, Val Acc: 0.5900\n",
      "GAT Epoch: 030, Loss: 0.5714, Train Acc: 0.7066, Val Acc: 0.7496\n",
      "GAT Epoch: 040, Loss: 0.4970, Train Acc: 0.8113, Val Acc: 0.8533\n",
      "GAT Epoch: 050, Loss: 0.4174, Train Acc: 0.9364, Val Acc: 0.9104\n",
      "GAT Epoch: 060, Loss: 0.3802, Train Acc: 0.9063, Val Acc: 0.9008\n",
      "GAT Epoch: 070, Loss: 0.3518, Train Acc: 0.8621, Val Acc: 0.8759\n",
      "GAT Epoch: 080, Loss: 0.3251, Train Acc: 0.8627, Val Acc: 0.8771\n",
      "GAT Epoch: 090, Loss: 0.3102, Train Acc: 0.8492, Val Acc: 0.8711\n",
      "GAT Epoch: 100, Loss: 0.2989, Train Acc: 0.8868, Val Acc: 0.8890\n",
      "GAT Epoch: 110, Loss: 0.2879, Train Acc: 0.9264, Val Acc: 0.9025\n",
      "GAT Epoch: 120, Loss: 0.2781, Train Acc: 0.9374, Val Acc: 0.8973\n",
      "GAT Epoch: 130, Loss: 0.2692, Train Acc: 0.9387, Val Acc: 0.8937\n",
      "GAT Epoch: 140, Loss: 0.2655, Train Acc: 0.9395, Val Acc: 0.8933\n",
      "GAT Epoch: 150, Loss: 0.2574, Train Acc: 0.9397, Val Acc: 0.8920\n",
      "GAT Epoch: 160, Loss: 0.2534, Train Acc: 0.9397, Val Acc: 0.8915\n",
      "GAT Epoch: 170, Loss: 0.2493, Train Acc: 0.9399, Val Acc: 0.8915\n",
      "GAT Epoch: 180, Loss: 0.2454, Train Acc: 0.9402, Val Acc: 0.8911\n",
      "GAT Epoch: 190, Loss: 0.2420, Train Acc: 0.9402, Val Acc: 0.8909\n",
      "GAT Epoch: 200, Loss: 0.2386, Train Acc: 0.9402, Val Acc: 0.8907\n",
      "GAT Test Accuracy: 0.9066\n",
      "GAT Training Time: 419.75 seconds\n",
      "GraphSAGE Epoch: 010, Loss: 0.2371, Train Acc: 0.9354, Val Acc: 0.8997\n",
      "GraphSAGE Epoch: 020, Loss: 0.1762, Train Acc: 0.9417, Val Acc: 0.8939\n",
      "GraphSAGE Epoch: 030, Loss: 0.1570, Train Acc: 0.9432, Val Acc: 0.8969\n",
      "GraphSAGE Epoch: 040, Loss: 0.1467, Train Acc: 0.9482, Val Acc: 0.9130\n",
      "GraphSAGE Epoch: 050, Loss: 0.1404, Train Acc: 0.9512, Val Acc: 0.9182\n",
      "GraphSAGE Epoch: 060, Loss: 0.1366, Train Acc: 0.9549, Val Acc: 0.9272\n",
      "GraphSAGE Epoch: 070, Loss: 0.1325, Train Acc: 0.9574, Val Acc: 0.9334\n",
      "GraphSAGE Epoch: 080, Loss: 0.1286, Train Acc: 0.9600, Val Acc: 0.9403\n",
      "GraphSAGE Epoch: 090, Loss: 0.1250, Train Acc: 0.9616, Val Acc: 0.9461\n",
      "GraphSAGE Epoch: 100, Loss: 0.1235, Train Acc: 0.9629, Val Acc: 0.9489\n",
      "GraphSAGE Epoch: 110, Loss: 0.1210, Train Acc: 0.9641, Val Acc: 0.9517\n",
      "GraphSAGE Epoch: 120, Loss: 0.1196, Train Acc: 0.9649, Val Acc: 0.9536\n",
      "GraphSAGE Epoch: 130, Loss: 0.1171, Train Acc: 0.9658, Val Acc: 0.9585\n",
      "GraphSAGE Epoch: 140, Loss: 0.1152, Train Acc: 0.9663, Val Acc: 0.9598\n",
      "GraphSAGE Epoch: 150, Loss: 0.1140, Train Acc: 0.9666, Val Acc: 0.9594\n",
      "GraphSAGE Epoch: 160, Loss: 0.1132, Train Acc: 0.9672, Val Acc: 0.9594\n",
      "GraphSAGE Epoch: 170, Loss: 0.1124, Train Acc: 0.9675, Val Acc: 0.9605\n",
      "GraphSAGE Epoch: 180, Loss: 0.1115, Train Acc: 0.9679, Val Acc: 0.9618\n",
      "GraphSAGE Epoch: 190, Loss: 0.1100, Train Acc: 0.9682, Val Acc: 0.9620\n",
      "GraphSAGE Epoch: 200, Loss: 0.1096, Train Acc: 0.9684, Val Acc: 0.9620\n",
      "GraphSAGE Test Accuracy: 0.9652\n",
      "GraphSAGE Training Time: 75.30 seconds\n",
      "\n",
      "==================== label_propagation_gat Results ====================\n",
      "Model: label_propagation_gat\n",
      "Test Accuracy: 0.9066\n",
      "Validation Accuracy: 0.9117\n",
      "Training Time (s): 419.75\n",
      "Final Training Loss: 0.2386\n",
      "Number of Epochs: 200\n",
      "==================================================\n",
      "\n",
      "==================== label_propagation_sage Results ====================\n",
      "Model: label_propagation_sage\n",
      "Test Accuracy: 0.9652\n",
      "Validation Accuracy: 0.9637\n",
      "Training Time (s): 75.30\n",
      "Final Training Loss: 0.1096\n",
      "Number of Epochs: 200\n",
      "==================================================\n",
      "GAT Epoch: 010, Loss: 0.8392, Train Acc: 0.9551, Val Acc: 0.8892\n",
      "GAT Epoch: 020, Loss: 0.6842, Train Acc: 0.9541, Val Acc: 0.8937\n",
      "GAT Epoch: 030, Loss: 0.4867, Train Acc: 0.7554, Val Acc: 0.6572\n",
      "GAT Epoch: 040, Loss: 0.4058, Train Acc: 0.8807, Val Acc: 0.7537\n",
      "GAT Epoch: 050, Loss: 0.3535, Train Acc: 0.9004, Val Acc: 0.7792\n",
      "GAT Epoch: 060, Loss: 0.3265, Train Acc: 0.9323, Val Acc: 0.8475\n",
      "GAT Epoch: 070, Loss: 0.2939, Train Acc: 0.9278, Val Acc: 0.8351\n",
      "GAT Epoch: 080, Loss: 0.2736, Train Acc: 0.9319, Val Acc: 0.8406\n",
      "GAT Epoch: 090, Loss: 0.2597, Train Acc: 0.9363, Val Acc: 0.8494\n",
      "GAT Epoch: 100, Loss: 0.2474, Train Acc: 0.9436, Val Acc: 0.8664\n",
      "GAT Epoch: 110, Loss: 0.2343, Train Acc: 0.9477, Val Acc: 0.8726\n",
      "GAT Epoch: 120, Loss: 0.2250, Train Acc: 0.9524, Val Acc: 0.8834\n",
      "GAT Epoch: 130, Loss: 0.2151, Train Acc: 0.9541, Val Acc: 0.8883\n",
      "GAT Epoch: 140, Loss: 0.2106, Train Acc: 0.9570, Val Acc: 0.8943\n",
      "GAT Epoch: 150, Loss: 0.2039, Train Acc: 0.9594, Val Acc: 0.8993\n",
      "GAT Epoch: 160, Loss: 0.1989, Train Acc: 0.9614, Val Acc: 0.9034\n",
      "GAT Epoch: 170, Loss: 0.1941, Train Acc: 0.9626, Val Acc: 0.9025\n",
      "GAT Epoch: 180, Loss: 0.1892, Train Acc: 0.9627, Val Acc: 0.9057\n",
      "GAT Epoch: 190, Loss: 0.1860, Train Acc: 0.9626, Val Acc: 0.9046\n",
      "GAT Epoch: 200, Loss: 0.1818, Train Acc: 0.9624, Val Acc: 0.9038\n",
      "GAT Test Accuracy: 0.9182\n",
      "GAT Training Time: 422.02 seconds\n",
      "GraphSAGE Epoch: 010, Loss: 0.2032, Train Acc: 0.9570, Val Acc: 0.8909\n",
      "GraphSAGE Epoch: 020, Loss: 0.1219, Train Acc: 0.9605, Val Acc: 0.9036\n",
      "GraphSAGE Epoch: 030, Loss: 0.1038, Train Acc: 0.9628, Val Acc: 0.9072\n",
      "GraphSAGE Epoch: 040, Loss: 0.0915, Train Acc: 0.9621, Val Acc: 0.9040\n",
      "GraphSAGE Epoch: 050, Loss: 0.0817, Train Acc: 0.9714, Val Acc: 0.9272\n",
      "GraphSAGE Epoch: 060, Loss: 0.0742, Train Acc: 0.9761, Val Acc: 0.9409\n",
      "GraphSAGE Epoch: 070, Loss: 0.0688, Train Acc: 0.9794, Val Acc: 0.9489\n",
      "GraphSAGE Epoch: 080, Loss: 0.0656, Train Acc: 0.9812, Val Acc: 0.9536\n",
      "GraphSAGE Epoch: 090, Loss: 0.0618, Train Acc: 0.9823, Val Acc: 0.9575\n",
      "GraphSAGE Epoch: 100, Loss: 0.0606, Train Acc: 0.9835, Val Acc: 0.9618\n",
      "GraphSAGE Epoch: 110, Loss: 0.0576, Train Acc: 0.9846, Val Acc: 0.9637\n",
      "GraphSAGE Epoch: 120, Loss: 0.0560, Train Acc: 0.9855, Val Acc: 0.9659\n",
      "GraphSAGE Epoch: 130, Loss: 0.0547, Train Acc: 0.9865, Val Acc: 0.9691\n",
      "GraphSAGE Epoch: 140, Loss: 0.0534, Train Acc: 0.9871, Val Acc: 0.9699\n",
      "GraphSAGE Epoch: 150, Loss: 0.0528, Train Acc: 0.9875, Val Acc: 0.9714\n",
      "GraphSAGE Epoch: 160, Loss: 0.0506, Train Acc: 0.9877, Val Acc: 0.9710\n",
      "GraphSAGE Epoch: 170, Loss: 0.0502, Train Acc: 0.9880, Val Acc: 0.9721\n",
      "GraphSAGE Epoch: 180, Loss: 0.0489, Train Acc: 0.9883, Val Acc: 0.9719\n",
      "GraphSAGE Epoch: 190, Loss: 0.0485, Train Acc: 0.9885, Val Acc: 0.9734\n",
      "GraphSAGE Epoch: 200, Loss: 0.0469, Train Acc: 0.9886, Val Acc: 0.9734\n",
      "GraphSAGE Test Accuracy: 0.9704\n",
      "GraphSAGE Training Time: 76.13 seconds\n",
      "\n",
      "==================== gat_gat Results ====================\n",
      "Model: gat_gat\n",
      "Test Accuracy: 0.9182\n",
      "Validation Accuracy: 0.9064\n",
      "Training Time (s): 422.02\n",
      "Final Training Loss: 0.1818\n",
      "Number of Epochs: 200\n",
      "==================================================\n",
      "\n",
      "==================== gat_sage Results ====================\n",
      "Model: gat_sage\n",
      "Test Accuracy: 0.9704\n",
      "Validation Accuracy: 0.9738\n",
      "Training Time (s): 76.13\n",
      "Final Training Loss: 0.0469\n",
      "Number of Epochs: 200\n",
      "==================================================\n",
      "GAT Epoch: 010, Loss: 0.9191, Train Acc: 0.9559, Val Acc: 0.8902\n",
      "GAT Epoch: 020, Loss: 0.7367, Train Acc: 0.9496, Val Acc: 0.8913\n",
      "GAT Epoch: 030, Loss: 0.5664, Train Acc: 0.8953, Val Acc: 0.8471\n",
      "GAT Epoch: 040, Loss: 0.4552, Train Acc: 0.7629, Val Acc: 0.6871\n",
      "GAT Epoch: 050, Loss: 0.3801, Train Acc: 0.9462, Val Acc: 0.8909\n",
      "GAT Epoch: 060, Loss: 0.3413, Train Acc: 0.9407, Val Acc: 0.8823\n",
      "GAT Epoch: 070, Loss: 0.3120, Train Acc: 0.9572, Val Acc: 0.9036\n",
      "GAT Epoch: 080, Loss: 0.2905, Train Acc: 0.9265, Val Acc: 0.8595\n",
      "GAT Epoch: 090, Loss: 0.2703, Train Acc: 0.9439, Val Acc: 0.8776\n",
      "GAT Epoch: 100, Loss: 0.2577, Train Acc: 0.9408, Val Acc: 0.8746\n",
      "GAT Epoch: 110, Loss: 0.2429, Train Acc: 0.9428, Val Acc: 0.8782\n",
      "GAT Epoch: 120, Loss: 0.2369, Train Acc: 0.9502, Val Acc: 0.8883\n",
      "GAT Epoch: 130, Loss: 0.2248, Train Acc: 0.9537, Val Acc: 0.8902\n",
      "GAT Epoch: 140, Loss: 0.2167, Train Acc: 0.9582, Val Acc: 0.8963\n",
      "GAT Epoch: 150, Loss: 0.2109, Train Acc: 0.9601, Val Acc: 0.9029\n",
      "GAT Epoch: 160, Loss: 0.2059, Train Acc: 0.9610, Val Acc: 0.9027\n",
      "GAT Epoch: 170, Loss: 0.1993, Train Acc: 0.9613, Val Acc: 0.9014\n",
      "GAT Epoch: 180, Loss: 0.1962, Train Acc: 0.9611, Val Acc: 0.9014\n",
      "GAT Epoch: 190, Loss: 0.1908, Train Acc: 0.9609, Val Acc: 0.9001\n",
      "GAT Epoch: 200, Loss: 0.1879, Train Acc: 0.9610, Val Acc: 0.9012\n",
      "GAT Test Accuracy: 0.9160\n",
      "GAT Training Time: 428.04 seconds\n",
      "GraphSAGE Epoch: 010, Loss: 0.2470, Train Acc: 0.9570, Val Acc: 0.8905\n",
      "GraphSAGE Epoch: 020, Loss: 0.1552, Train Acc: 0.9613, Val Acc: 0.9049\n",
      "GraphSAGE Epoch: 030, Loss: 0.1217, Train Acc: 0.9686, Val Acc: 0.9274\n",
      "GraphSAGE Epoch: 040, Loss: 0.0962, Train Acc: 0.9694, Val Acc: 0.9227\n",
      "GraphSAGE Epoch: 050, Loss: 0.0864, Train Acc: 0.9718, Val Acc: 0.9285\n",
      "GraphSAGE Epoch: 060, Loss: 0.0771, Train Acc: 0.9770, Val Acc: 0.9409\n",
      "GraphSAGE Epoch: 070, Loss: 0.0715, Train Acc: 0.9797, Val Acc: 0.9500\n",
      "GraphSAGE Epoch: 080, Loss: 0.0669, Train Acc: 0.9818, Val Acc: 0.9560\n",
      "GraphSAGE Epoch: 090, Loss: 0.0643, Train Acc: 0.9829, Val Acc: 0.9594\n",
      "GraphSAGE Epoch: 100, Loss: 0.0620, Train Acc: 0.9838, Val Acc: 0.9611\n",
      "GraphSAGE Epoch: 110, Loss: 0.0604, Train Acc: 0.9846, Val Acc: 0.9639\n",
      "GraphSAGE Epoch: 120, Loss: 0.0583, Train Acc: 0.9850, Val Acc: 0.9652\n",
      "GraphSAGE Epoch: 130, Loss: 0.0571, Train Acc: 0.9856, Val Acc: 0.9680\n",
      "GraphSAGE Epoch: 140, Loss: 0.0550, Train Acc: 0.9859, Val Acc: 0.9682\n",
      "GraphSAGE Epoch: 150, Loss: 0.0540, Train Acc: 0.9864, Val Acc: 0.9689\n",
      "GraphSAGE Epoch: 160, Loss: 0.0531, Train Acc: 0.9869, Val Acc: 0.9701\n",
      "GraphSAGE Epoch: 170, Loss: 0.0524, Train Acc: 0.9874, Val Acc: 0.9714\n",
      "GraphSAGE Epoch: 180, Loss: 0.0502, Train Acc: 0.9878, Val Acc: 0.9721\n",
      "GraphSAGE Epoch: 190, Loss: 0.0499, Train Acc: 0.9880, Val Acc: 0.9719\n",
      "GraphSAGE Epoch: 200, Loss: 0.0489, Train Acc: 0.9882, Val Acc: 0.9725\n",
      "GraphSAGE Test Accuracy: 0.9704\n",
      "GraphSAGE Training Time: 76.34 seconds\n",
      "\n",
      "==================== sage_gat Results ====================\n",
      "Model: sage_gat\n",
      "Test Accuracy: 0.9160\n",
      "Validation Accuracy: 0.9091\n",
      "Training Time (s): 428.04\n",
      "Final Training Loss: 0.1879\n",
      "Number of Epochs: 200\n",
      "==================================================\n",
      "\n",
      "==================== sage_sage Results ====================\n",
      "Model: sage_sage\n",
      "Test Accuracy: 0.9704\n",
      "Validation Accuracy: 0.9727\n",
      "Training Time (s): 76.34\n",
      "Final Training Loss: 0.0489\n",
      "Number of Epochs: 200\n",
      "==================================================\n",
      "\n",
      "==== Step 7: Analyzing Graph Properties with Augmented Models ====\n",
      "Unknown nodes predicted as licit: 124\n",
      "Unknown nodes predicted as illicit: 157081\n",
      "Processed train_licit: 3602 nodes, 651 edges\n",
      "Processed train_illicit: 33649 nodes, 21207 edges\n",
      "Processed val_licit: 508 nodes, 18 edges\n",
      "Processed val_illicit: 4148 nodes, 379 edges\n",
      "Processed test_licit: 435 nodes, 8 edges\n",
      "Processed test_illicit: 4222 nodes, 394 edges\n",
      "Processed unknown: 157205 nodes, 131778 edges\n",
      "Processed pred_unknown_licit: 124 nodes, 0 edges\n",
      "Processed pred_unknown_illicit: 157081 nodes, 131750 edges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuhuizhan/BTCGraphGuard/venv/lib/python3.10/site-packages/pandas/plotting/_matplotlib/core.py:580: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig = self.plt.figure(figsize=self.figsize)\n",
      "/var/folders/m4/lr92jqdj1_z4cm26h66ndqy40000gn/T/ipykernel_46169/2403487962.py:256: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure(figsize=(12, 8))\n",
      "/var/folders/m4/lr92jqdj1_z4cm26h66ndqy40000gn/T/ipykernel_46169/2403487962.py:309: UserWarning: Dataset has 0 variance; skipping density estimate. Pass `warn_singular=False` to disable this warning.\n",
      "  sns.kdeplot(group_data['degree_centrality'], label=group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete. Results saved to output/comprehensive_analysis_20250410_171856/augmented/label/propagation/graph_properties_with_model\n",
      "Unknown nodes predicted as licit: 4989\n",
      "Unknown nodes predicted as illicit: 152216\n",
      "Processed train_licit: 3602 nodes, 651 edges\n",
      "Processed train_illicit: 33649 nodes, 21207 edges\n",
      "Processed val_licit: 508 nodes, 18 edges\n",
      "Processed val_illicit: 4148 nodes, 379 edges\n",
      "Processed test_licit: 435 nodes, 8 edges\n",
      "Processed test_illicit: 4222 nodes, 394 edges\n",
      "Processed unknown: 157205 nodes, 131778 edges\n",
      "Processed pred_unknown_licit: 4989 nodes, 1299 edges\n",
      "Processed pred_unknown_illicit: 152216 nodes, 124705 edges\n",
      "Analysis complete. Results saved to output/comprehensive_analysis_20250410_171856/augmented/label/propagation/graph_properties_with_model\n",
      "Unknown nodes predicted as licit: 5862\n",
      "Unknown nodes predicted as illicit: 151343\n",
      "Processed train_licit: 3602 nodes, 651 edges\n",
      "Processed train_illicit: 33649 nodes, 21207 edges\n",
      "Processed val_licit: 508 nodes, 18 edges\n",
      "Processed val_illicit: 4148 nodes, 379 edges\n",
      "Processed test_licit: 435 nodes, 8 edges\n",
      "Processed test_illicit: 4222 nodes, 394 edges\n",
      "Processed unknown: 157205 nodes, 131778 edges\n",
      "Processed pred_unknown_licit: 5862 nodes, 1459 edges\n",
      "Processed pred_unknown_illicit: 151343 nodes, 127114 edges\n",
      "Analysis complete. Results saved to output/comprehensive_analysis_20250410_171856/augmented/gat/gat/graph_properties_with_model\n",
      "Unknown nodes predicted as licit: 8038\n",
      "Unknown nodes predicted as illicit: 149167\n",
      "Processed train_licit: 3602 nodes, 651 edges\n",
      "Processed train_illicit: 33649 nodes, 21207 edges\n",
      "Processed val_licit: 508 nodes, 18 edges\n",
      "Processed val_illicit: 4148 nodes, 379 edges\n",
      "Processed test_licit: 435 nodes, 8 edges\n",
      "Processed test_illicit: 4222 nodes, 394 edges\n",
      "Processed unknown: 157205 nodes, 131778 edges\n",
      "Processed pred_unknown_licit: 8038 nodes, 1108 edges\n",
      "Processed pred_unknown_illicit: 149167 nodes, 121987 edges\n",
      "Analysis complete. Results saved to output/comprehensive_analysis_20250410_171856/augmented/gat/sage/graph_properties_with_model\n",
      "Unknown nodes predicted as licit: 3207\n",
      "Unknown nodes predicted as illicit: 153998\n",
      "Processed train_licit: 3602 nodes, 651 edges\n",
      "Processed train_illicit: 33649 nodes, 21207 edges\n",
      "Processed val_licit: 508 nodes, 18 edges\n",
      "Processed val_illicit: 4148 nodes, 379 edges\n",
      "Processed test_licit: 435 nodes, 8 edges\n",
      "Processed test_illicit: 4222 nodes, 394 edges\n",
      "Processed unknown: 157205 nodes, 131778 edges\n",
      "Processed pred_unknown_licit: 3207 nodes, 433 edges\n",
      "Processed pred_unknown_illicit: 153998 nodes, 129682 edges\n",
      "Analysis complete. Results saved to output/comprehensive_analysis_20250410_171856/augmented/sage/gat/graph_properties_with_model\n",
      "Unknown nodes predicted as licit: 8365\n",
      "Unknown nodes predicted as illicit: 148840\n",
      "Processed train_licit: 3602 nodes, 651 edges\n",
      "Processed train_illicit: 33649 nodes, 21207 edges\n",
      "Processed val_licit: 508 nodes, 18 edges\n",
      "Processed val_illicit: 4148 nodes, 379 edges\n",
      "Processed test_licit: 435 nodes, 8 edges\n",
      "Processed test_illicit: 4222 nodes, 394 edges\n",
      "Processed unknown: 157205 nodes, 131778 edges\n",
      "Processed pred_unknown_licit: 8365 nodes, 1002 edges\n",
      "Processed pred_unknown_illicit: 148840 nodes, 121404 edges\n",
      "Analysis complete. Results saved to output/comprehensive_analysis_20250410_171856/augmented/sage/sage/graph_properties_with_model\n",
      "\n",
      "==== Step 8: Saving Important Metrics ====\n",
      "\n",
      "==== Step 9: Creating Comprehensive Comparison ====\n",
      "\n",
      "    ===== ANALYSIS CONCLUSION =====\n",
      "    \n",
      "    Best Overall Model: base_sage\n",
      "    Test Accuracy: 0.9740\n",
      "    Graph Consistency Score: 1.0000\n",
      "    Combined Score: 0.9844\n",
      "    Training Time: 76.91 seconds\n",
      "    \n",
      "    Key Findings:\n",
      "    - The best model for test accuracy was: base_sage (0.9740)\n",
      "    - The best model for graph consistency was: base_gat (1.0000)\n",
      "    - The fastest model was: label_propagation_sage (75.30 seconds)\n",
      "    \n",
      "    Recommendation:\n",
      "    The base_sage model provides the best balance between prediction accuracy and graph structure preservation.\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = comprehensive_graph_analysis(data, epochs=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
