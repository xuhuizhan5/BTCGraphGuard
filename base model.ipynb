{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Models for BTCGraphGuard\n",
    "\n",
    "**Authors: Xuhui Zhan, Tianhao Qu, Siyu Yang**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T21:45:09.440677Z",
     "start_time": "2025-04-05T21:45:04.259682Z"
    }
   },
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import time"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda_envs\\graphhw3\\lib\\site-packages\\torch_geometric\\typing.py:68: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: [WinError 127] La procédure spécifiée est introuvable\n",
      "  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n",
      "E:\\anaconda_envs\\graphhw3\\lib\\site-packages\\torch_geometric\\typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: [WinError 127] La procédure spécifiée est introuvable\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "E:\\anaconda_envs\\graphhw3\\lib\\site-packages\\torch_geometric\\typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: [WinError 127] La procédure spécifiée est introuvable\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
      "E:\\anaconda_envs\\graphhw3\\lib\\site-packages\\torch_geometric\\typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: [WinError 127] La procédure spécifiée est introuvable\n",
      "  warnings.warn(\n",
      "E:\\anaconda_envs\\graphhw3\\lib\\site-packages\\torch_geometric\\typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: [WinError 127] La procédure spécifiée est introuvable\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T21:45:12.456019Z",
     "start_time": "2025-04-05T21:45:09.440677Z"
    }
   },
   "source": [
    "# Prepare Data\n",
    "data_root = './elliptic_bitcoin_dataset'\n",
    "elliptic_txs_features = pd.read_csv(os.path.join(data_root, 'elliptic_txs_features.csv'), header=None)\n",
    "elliptic_txs_edgelist = pd.read_csv(os.path.join(data_root, 'elliptic_txs_edgelist.csv'))\n",
    "elliptic_txs_classes = pd.read_csv(os.path.join(data_root, 'elliptic_txs_classes.csv'))\n",
    "\n",
    "elliptic_txs_features.columns = ['txId'] + [f'V{i}' for i in range(1, 167)]\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T21:45:12.654762Z",
     "start_time": "2025-04-05T21:45:12.649721Z"
    }
   },
   "source": [
    "print(elliptic_txs_features.shape)\n",
    "print(elliptic_txs_edgelist.shape)\n",
    "print(elliptic_txs_classes.shape)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(203769, 167)\n",
      "(234355, 2)\n",
      "(203769, 2)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T21:45:12.726253Z",
     "start_time": "2025-04-05T21:45:12.689592Z"
    }
   },
   "source": [
    "elliptic_txs_classes['class_mapped'] = elliptic_txs_classes['class'].replace({'1': 'illicit', '2': 'licit'})"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T21:45:13.109461Z",
     "start_time": "2025-04-05T21:45:12.726253Z"
    }
   },
   "source": [
    "# Create Graph\n",
    "G = nx.from_pandas_edgelist(elliptic_txs_edgelist, 'txId1', 'txId2')"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random seed settings"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T21:45:13.210311Z",
     "start_time": "2025-04-05T21:45:13.202919Z"
    }
   },
   "source": [
    "RANDOM_STATE = 42\n",
    "NUM_EPOCHS = 30"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T21:45:13.226228Z",
     "start_time": "2025-04-05T21:45:13.210311Z"
    }
   },
   "source": [
    "def set_seed_for_torch(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)      # For single-GPU.\n",
    "        torch.cuda.manual_seed_all(seed)  # For multi-GPU.\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "def set_seed_for_numpy(seed):\n",
    "    np.random.seed(seed) \n",
    "    \n",
    "def set_seed_for_random(seed):\n",
    "    random.seed(seed)  "
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T21:45:13.288897Z",
     "start_time": "2025-04-05T21:45:13.273154Z"
    }
   },
   "source": [
    "set_seed_for_torch(RANDOM_STATE)\n",
    "set_seed_for_numpy(RANDOM_STATE)\n",
    "set_seed_for_random(RANDOM_STATE)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T21:45:13.356208Z",
     "start_time": "2025-04-05T21:45:13.345483Z"
    }
   },
   "source": [
    "# Spaceholders for EDA"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T21:45:13.607063Z",
     "start_time": "2025-04-05T21:45:13.406169Z"
    }
   },
   "source": [
    "tx_id_mapping = {tx_id: idx for idx, tx_id in enumerate(elliptic_txs_features['txId'])}\n",
    "\n",
    "# Create an explicit copy of the filtered DataFrame\n",
    "edges_with_features = elliptic_txs_edgelist[elliptic_txs_edgelist['txId1'].isin(list(tx_id_mapping.keys())) & \n",
    "                                           elliptic_txs_edgelist['txId2'].isin(list(tx_id_mapping.keys()))].copy()\n",
    "\n",
    "# Now use loc to set values (though with copy() above, direct assignment would also work)\n",
    "edges_with_features.loc[:, 'Id1'] = edges_with_features['txId1'].map(tx_id_mapping)\n",
    "edges_with_features.loc[:, 'Id2'] = edges_with_features['txId2'].map(tx_id_mapping)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T21:45:13.799313Z",
     "start_time": "2025-04-05T21:45:13.668007Z"
    }
   },
   "source": [
    "edge_index = torch.tensor(edges_with_features[['Id1', 'Id2']].values.T, dtype=torch.long)\n",
    "node_features = torch.tensor(elliptic_txs_features.drop(columns=['txId']).values, \n",
    "                             dtype=torch.float)"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T21:45:13.901038Z",
     "start_time": "2025-04-05T21:45:13.869642Z"
    }
   },
   "source": [
    "le = LabelEncoder()\n",
    "class_labels = le.fit_transform(elliptic_txs_classes['class'])\n",
    "node_labels = torch.tensor(class_labels, dtype=torch.long)\n",
    "original_labels = le.inverse_transform(class_labels)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T21:45:13.994254Z",
     "start_time": "2025-04-05T21:45:13.981108Z"
    }
   },
   "source": [
    "data = Data(x=node_features, \n",
    "            edge_index=edge_index, \n",
    "            y=node_labels)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T21:45:14.084806Z",
     "start_time": "2025-04-05T21:45:14.066308Z"
    }
   },
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T21:45:14.173902Z",
     "start_time": "2025-04-05T21:45:14.158226Z"
    }
   },
   "source": [
    "known_mask   = (data.y == 0) | (data.y == 1)  # Only nodes with known labels licit or illicit\n",
    "unknown_mask = data.y == 2                    # Nodes with unknown labels"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T21:45:14.251967Z",
     "start_time": "2025-04-05T21:45:14.245200Z"
    }
   },
   "source": [
    "num_known_nodes = known_mask.sum().item()\n",
    "permutations = torch.randperm(num_known_nodes)\n",
    "train_size = int(0.8 * num_known_nodes)\n",
    "val_size = int(0.1 * num_known_nodes)\n",
    "test_size = num_known_nodes - train_size - val_size\n",
    "\n",
    "total = np.sum([train_size, val_size, test_size])\n",
    "\n",
    "print(f\"\"\"Number of observations per split\n",
    "    Training   : {train_size:10,} ({100*train_size/total:0.2f} %)\n",
    "    Validation : {val_size:10,} ({100*val_size/total:0.2f} %)\n",
    "    Testing    : {test_size:10,} ({100*test_size/total:0.2f} %)\n",
    "\"\"\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations per split\n",
      "    Training   :     37,251 (80.00 %)\n",
      "    Validation :      4,656 (10.00 %)\n",
      "    Testing    :      4,657 (10.00 %)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T21:45:14.342531Z",
     "start_time": "2025-04-05T21:45:14.327334Z"
    }
   },
   "source": [
    "data.train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "data.val_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "data.test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "\n",
    "train_indices = known_mask.nonzero(as_tuple=True)[0][permutations[:train_size]]\n",
    "val_indices = known_mask.nonzero(as_tuple=True)[0][permutations[train_size:train_size + val_size]]\n",
    "test_indices = known_mask.nonzero(as_tuple=True)[0][permutations[train_size + val_size:]]\n",
    "\n",
    "data.train_mask[train_indices] = True\n",
    "data.val_mask[val_indices] = True\n",
    "data.test_mask[test_indices] = True\n",
    "\n",
    "print(len(data.train_mask))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203769\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Graph attention network (GAT)"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T22:23:50.206486Z",
     "start_time": "2025-04-05T22:23:33.883078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create output directory if it doesn't exist\n",
    "output_dir = \"output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "data = data.to(device)\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, heads=8):\n",
    "        super(GAT, self).__init__()\n",
    "        self.conv1 = GATConv(input_dim, hidden_dim, heads=heads, dropout=0.6)\n",
    "        self.conv2 = GATConv(hidden_dim * heads, output_dim, heads=1, concat=False, dropout=0.6)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "gat_model = GAT(input_dim, hidden_dim, output_dim).to(device)\n",
    "optimizer_gat = torch.optim.Adam(gat_model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train_gat():\n",
    "    gat_model.train()\n",
    "    optimizer_gat.zero_grad()\n",
    "    out = gat_model(data)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer_gat.step()\n",
    "    return loss.item()\n",
    "\n",
    "def evaluate_gat(mask):\n",
    "    gat_model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = gat_model(data)\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct = pred[mask] == data.y[mask]\n",
    "        acc = int(correct.sum()) / int(mask.sum())\n",
    "    return acc\n",
    "\n",
    "num_epochs = 200\n",
    "best_val_acc_gat = 0\n",
    "best_model_gat = None\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    loss = train_gat()\n",
    "    train_acc = evaluate_gat(data.train_mask)\n",
    "    val_acc = evaluate_gat(data.val_mask)\n",
    "    if val_acc > best_val_acc_gat:\n",
    "        best_val_acc_gat = val_acc\n",
    "        best_model_gat = gat_model.state_dict()\n",
    "        torch.save(best_model_gat, os.path.join(output_dir, \"gat_best_model.pt\"))\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'GAT Epoch: {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
    "gat_training_time = time.time() - start_time\n",
    "gat_model.load_state_dict(best_model_gat)\n",
    "test_acc_gat = evaluate_gat(data.test_mask)\n",
    "print(f'GAT Test Accuracy: {test_acc_gat:.4f}')\n",
    "print(f'GAT Training Time: {gat_training_time:.2f} seconds')\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAT Epoch: 010, Loss: 1.1814, Train Acc: 0.5571, Val Acc: 0.5533\n",
      "GAT Epoch: 020, Loss: 0.8016, Train Acc: 0.7138, Val Acc: 0.7083\n",
      "GAT Epoch: 030, Loss: 0.6742, Train Acc: 0.7323, Val Acc: 0.7249\n",
      "GAT Epoch: 040, Loss: 0.5796, Train Acc: 0.8281, Val Acc: 0.8250\n",
      "GAT Epoch: 050, Loss: 0.5292, Train Acc: 0.8432, Val Acc: 0.8393\n",
      "GAT Epoch: 060, Loss: 0.4952, Train Acc: 0.8567, Val Acc: 0.8501\n",
      "GAT Epoch: 070, Loss: 0.4713, Train Acc: 0.8655, Val Acc: 0.8540\n",
      "GAT Epoch: 080, Loss: 0.4548, Train Acc: 0.8658, Val Acc: 0.8542\n",
      "GAT Epoch: 090, Loss: 0.4361, Train Acc: 0.8837, Val Acc: 0.8752\n",
      "GAT Epoch: 100, Loss: 0.4261, Train Acc: 0.8617, Val Acc: 0.8512\n",
      "GAT Epoch: 110, Loss: 0.4141, Train Acc: 0.8918, Val Acc: 0.8829\n",
      "GAT Epoch: 120, Loss: 0.4030, Train Acc: 0.8801, Val Acc: 0.8709\n",
      "GAT Epoch: 130, Loss: 0.3898, Train Acc: 0.8982, Val Acc: 0.8922\n",
      "GAT Epoch: 140, Loss: 0.3816, Train Acc: 0.9193, Val Acc: 0.9098\n",
      "GAT Epoch: 150, Loss: 0.3727, Train Acc: 0.9036, Val Acc: 0.8984\n",
      "GAT Epoch: 160, Loss: 0.3640, Train Acc: 0.9053, Val Acc: 0.8978\n",
      "GAT Epoch: 170, Loss: 0.3584, Train Acc: 0.9194, Val Acc: 0.9098\n",
      "GAT Epoch: 180, Loss: 0.3528, Train Acc: 0.9201, Val Acc: 0.9100\n",
      "GAT Epoch: 190, Loss: 0.3471, Train Acc: 0.9186, Val Acc: 0.9087\n",
      "GAT Epoch: 200, Loss: 0.3438, Train Acc: 0.9122, Val Acc: 0.8997\n",
      "GAT Test Accuracy: 0.9167\n",
      "GAT Training Time: 16.17 seconds\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## GraphSAGE"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T22:27:18.387897Z",
     "start_time": "2025-04-05T22:27:14.918397Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(input_dim, hidden_dim)\n",
    "        self.conv2 = SAGEConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "sage_model = GraphSAGE(input_dim, hidden_dim, output_dim).to(device)\n",
    "optimizer_sage = torch.optim.Adam(sage_model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train_sage():\n",
    "    sage_model.train()\n",
    "    optimizer_sage.zero_grad()\n",
    "    out = sage_model(data)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer_sage.step()\n",
    "    return loss.item()\n",
    "\n",
    "def evaluate_sage(mask):\n",
    "    sage_model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = sage_model(data)\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct = pred[mask] == data.y[mask]\n",
    "        acc = int(correct.sum()) / int(mask.sum())\n",
    "    return acc\n",
    "\n",
    "num_epochs = 200\n",
    "best_val_acc_sage = 0\n",
    "best_model_sage = None\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    loss = train_sage()\n",
    "    train_acc = evaluate_sage(data.train_mask)\n",
    "    val_acc = evaluate_sage(data.val_mask)\n",
    "    if val_acc > best_val_acc_sage:\n",
    "        best_val_acc_sage = val_acc\n",
    "        best_model_sage = sage_model.state_dict()\n",
    "        # Save checkpoint in output folder\n",
    "        torch.save(best_model_sage, os.path.join(output_dir, \"sage_best_model.pt\"))\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'GraphSAGE Epoch: {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
    "sage_training_time = time.time() - start_time\n",
    "sage_model.load_state_dict(best_model_sage)\n",
    "test_acc_sage = evaluate_sage(data.test_mask)\n",
    "print(f'GraphSAGE Test Accuracy: {test_acc_sage:.4f}')\n",
    "print(f'GraphSAGE Training Time: {sage_training_time:.2f} seconds')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphSAGE Epoch: 010, Loss: 0.2360, Train Acc: 0.9227, Val Acc: 0.9180\n",
      "GraphSAGE Epoch: 020, Loss: 0.1739, Train Acc: 0.9411, Val Acc: 0.9369\n",
      "GraphSAGE Epoch: 030, Loss: 0.1480, Train Acc: 0.9621, Val Acc: 0.9620\n",
      "GraphSAGE Epoch: 040, Loss: 0.1335, Train Acc: 0.9653, Val Acc: 0.9637\n",
      "GraphSAGE Epoch: 050, Loss: 0.1222, Train Acc: 0.9691, Val Acc: 0.9693\n",
      "GraphSAGE Epoch: 060, Loss: 0.1146, Train Acc: 0.9725, Val Acc: 0.9729\n",
      "GraphSAGE Epoch: 070, Loss: 0.1061, Train Acc: 0.9748, Val Acc: 0.9747\n",
      "GraphSAGE Epoch: 080, Loss: 0.1012, Train Acc: 0.9763, Val Acc: 0.9762\n",
      "GraphSAGE Epoch: 090, Loss: 0.0970, Train Acc: 0.9771, Val Acc: 0.9766\n",
      "GraphSAGE Epoch: 100, Loss: 0.0916, Train Acc: 0.9788, Val Acc: 0.9770\n",
      "GraphSAGE Epoch: 110, Loss: 0.0906, Train Acc: 0.9788, Val Acc: 0.9770\n",
      "GraphSAGE Epoch: 120, Loss: 0.0874, Train Acc: 0.9794, Val Acc: 0.9770\n",
      "GraphSAGE Epoch: 130, Loss: 0.0857, Train Acc: 0.9802, Val Acc: 0.9785\n",
      "GraphSAGE Epoch: 140, Loss: 0.0823, Train Acc: 0.9805, Val Acc: 0.9796\n",
      "GraphSAGE Epoch: 150, Loss: 0.0809, Train Acc: 0.9812, Val Acc: 0.9798\n",
      "GraphSAGE Epoch: 160, Loss: 0.0796, Train Acc: 0.9810, Val Acc: 0.9790\n",
      "GraphSAGE Epoch: 170, Loss: 0.0780, Train Acc: 0.9818, Val Acc: 0.9800\n",
      "GraphSAGE Epoch: 180, Loss: 0.0781, Train Acc: 0.9818, Val Acc: 0.9809\n",
      "GraphSAGE Epoch: 190, Loss: 0.0757, Train Acc: 0.9824, Val Acc: 0.9800\n",
      "GraphSAGE Epoch: 200, Loss: 0.0727, Train Acc: 0.9820, Val Acc: 0.9800\n",
      "GraphSAGE Test Accuracy: 0.9762\n",
      "GraphSAGE Training Time: 3.43 seconds\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
