{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Models for BTCGraphGuard\n",
    "\n",
    "**Authors: Xuhui Zhan, Tianhao Qu, Siyu Yang**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T01:48:15.088529Z",
     "start_time": "2025-04-07T01:48:15.084030Z"
    }
   },
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.utils import from_networkx\n",
    "import time"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T00:55:21.950839Z",
     "start_time": "2025-04-07T00:55:18.838962Z"
    }
   },
   "source": [
    "# Prepare Data\n",
    "data_root = 'data/data/elliptic_bitcoin_dataset'\n",
    "elliptic_txs_features = pd.read_csv(os.path.join(data_root, 'elliptic_txs_features.csv'), header=None)\n",
    "elliptic_txs_edgelist = pd.read_csv(os.path.join(data_root, 'elliptic_txs_edgelist.csv'))\n",
    "elliptic_txs_classes = pd.read_csv(os.path.join(data_root, 'elliptic_txs_classes.csv'))\n",
    "\n",
    "elliptic_txs_features.columns = ['txId'] + [f'V{i}' for i in range(1, 167)]\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T00:55:23.908129Z",
     "start_time": "2025-04-07T00:55:23.905040Z"
    }
   },
   "source": [
    "print(elliptic_txs_features.shape)\n",
    "print(elliptic_txs_edgelist.shape)\n",
    "print(elliptic_txs_classes.shape)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(203769, 167)\n",
      "(234355, 2)\n",
      "(203769, 2)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T01:09:33.195956Z",
     "start_time": "2025-04-07T01:09:33.171203Z"
    }
   },
   "source": [
    "elliptic_txs_classes['class_mapped'] = elliptic_txs_classes['class'].replace({'1': 'illicit', '2': 'licit'})"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T01:09:34.482266Z",
     "start_time": "2025-04-07T01:09:33.723713Z"
    }
   },
   "source": [
    "# Create Graph\n",
    "G = nx.from_pandas_edgelist(elliptic_txs_edgelist, 'txId1', 'txId2')"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random seed settings"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T01:09:36.155117Z",
     "start_time": "2025-04-07T01:09:36.152694Z"
    }
   },
   "source": [
    "RANDOM_STATE = 42\n",
    "NUM_EPOCHS = 30"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T01:09:36.907170Z",
     "start_time": "2025-04-07T01:09:36.903171Z"
    }
   },
   "source": [
    "def set_seed_for_torch(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)      # For single-GPU.\n",
    "        torch.cuda.manual_seed_all(seed)  # For multi-GPU.\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "def set_seed_for_numpy(seed):\n",
    "    np.random.seed(seed) \n",
    "    \n",
    "def set_seed_for_random(seed):\n",
    "    random.seed(seed)  "
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T01:09:37.807822Z",
     "start_time": "2025-04-07T01:09:37.798822Z"
    }
   },
   "source": [
    "set_seed_for_torch(RANDOM_STATE)\n",
    "set_seed_for_numpy(RANDOM_STATE)\n",
    "set_seed_for_random(RANDOM_STATE)"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T21:45:13.356208Z",
     "start_time": "2025-04-05T21:45:13.345483Z"
    }
   },
   "source": [
    "# Spaceholders for EDA"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T01:10:22.940488Z",
     "start_time": "2025-04-07T01:10:22.742410Z"
    }
   },
   "source": [
    "tx_id_mapping = {tx_id: idx for idx, tx_id in enumerate(elliptic_txs_features['txId'])}\n",
    "\n",
    "# Create an explicit copy of the filtered DataFrame\n",
    "edges_with_features = elliptic_txs_edgelist[elliptic_txs_edgelist['txId1'].isin(list(tx_id_mapping.keys())) & \n",
    "                                           elliptic_txs_edgelist['txId2'].isin(list(tx_id_mapping.keys()))].copy()\n",
    "\n",
    "# Now use loc to set values (though with copy() above, direct assignment would also work)\n",
    "edges_with_features.loc[:, 'Id1'] = edges_with_features['txId1'].map(tx_id_mapping)\n",
    "edges_with_features.loc[:, 'Id2'] = edges_with_features['txId2'].map(tx_id_mapping)"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T01:10:23.654842Z",
     "start_time": "2025-04-07T01:10:23.548299Z"
    }
   },
   "source": [
    "edge_index = torch.tensor(edges_with_features[['Id1', 'Id2']].values.T, dtype=torch.long)\n",
    "node_features = torch.tensor(elliptic_txs_features.drop(columns=['txId']).values, \n",
    "                             dtype=torch.float)"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T01:10:24.115669Z",
     "start_time": "2025-04-07T01:10:24.093341Z"
    }
   },
   "source": [
    "le = LabelEncoder()\n",
    "class_labels = le.fit_transform(elliptic_txs_classes['class'])\n",
    "node_labels = torch.tensor(class_labels, dtype=torch.long)\n",
    "original_labels = le.inverse_transform(class_labels)"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T01:10:24.812006Z",
     "start_time": "2025-04-07T01:10:24.809006Z"
    }
   },
   "source": [
    "data = Data(x=node_features, \n",
    "            edge_index=edge_index, \n",
    "            y=node_labels)"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T01:10:25.511512Z",
     "start_time": "2025-04-07T01:10:25.508672Z"
    }
   },
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T01:10:28.084388Z",
     "start_time": "2025-04-07T01:10:28.078385Z"
    }
   },
   "source": [
    "known_mask   = (data.y == 0) | (data.y == 1)  # Only nodes with known labels licit or illicit\n",
    "unknown_mask = data.y == 2                    # Nodes with unknown labels"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T01:10:29.067259Z",
     "start_time": "2025-04-07T01:10:29.059912Z"
    }
   },
   "source": [
    "num_known_nodes = known_mask.sum().item()\n",
    "permutations = torch.randperm(num_known_nodes)\n",
    "train_size = int(0.8 * num_known_nodes)\n",
    "val_size = int(0.1 * num_known_nodes)\n",
    "test_size = num_known_nodes - train_size - val_size\n",
    "\n",
    "total = np.sum([train_size, val_size, test_size])\n",
    "\n",
    "print(f\"\"\"Number of observations per split\n",
    "    Training   : {train_size:10,} ({100*train_size/total:0.2f} %)\n",
    "    Validation : {val_size:10,} ({100*val_size/total:0.2f} %)\n",
    "    Testing    : {test_size:10,} ({100*test_size/total:0.2f} %)\n",
    "\"\"\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations per split\n",
      "    Training   :     37,251 (80.00 %)\n",
      "    Validation :      4,656 (10.00 %)\n",
      "    Testing    :      4,657 (10.00 %)\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T01:10:29.957245Z",
     "start_time": "2025-04-07T01:10:29.941750Z"
    }
   },
   "source": [
    "data.train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "data.val_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "data.test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "\n",
    "train_indices = known_mask.nonzero(as_tuple=True)[0][permutations[:train_size]]\n",
    "val_indices = known_mask.nonzero(as_tuple=True)[0][permutations[train_size:train_size + val_size]]\n",
    "test_indices = known_mask.nonzero(as_tuple=True)[0][permutations[train_size + val_size:]]\n",
    "\n",
    "data.train_mask[train_indices] = True\n",
    "data.val_mask[val_indices] = True\n",
    "data.test_mask[test_indices] = True\n",
    "\n",
    "print(len(data.train_mask))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203769\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph attention network (GAT)"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T01:26:58.751136Z",
     "start_time": "2025-04-07T01:16:54.561163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create output directory if it doesn't exist\n",
    "output_dir = \"output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "data = data.to(device)\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, heads=8):\n",
    "        super(GAT, self).__init__()\n",
    "        self.conv1 = GATConv(input_dim, hidden_dim, heads=heads, dropout=0.6)\n",
    "        self.conv2 = GATConv(hidden_dim * heads, output_dim, heads=1, concat=False, dropout=0.6)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "    \n",
    "def infer_model_dimensions(features_df, classes_df):\n",
    "    input_dim = features_df.shape[1] - 1\n",
    "\n",
    "    hidden_dim = 64\n",
    "\n",
    "    output_dim = classes_df['class'].dropna().nunique()\n",
    "\n",
    "    return input_dim, hidden_dim, output_dim\n",
    "features_df = pd.read_csv(os.path.join(data_root, 'elliptic_txs_features.csv'), header=None)\n",
    "classes_df = pd.read_csv(os.path.join(data_root, 'elliptic_txs_classes.csv'))\n",
    "\n",
    "input_dim, hidden_dim, output_dim = infer_model_dimensions(features_df,classes_df)\n",
    "gat_model = GAT(input_dim, hidden_dim, output_dim).to(device)\n",
    "optimizer_gat = torch.optim.Adam(gat_model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train_gat():\n",
    "    gat_model.train()\n",
    "    optimizer_gat.zero_grad()\n",
    "    out = gat_model(data)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer_gat.step()\n",
    "    return loss.item()\n",
    "\n",
    "def evaluate_gat(mask):\n",
    "    gat_model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = gat_model(data)\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct = pred[mask] == data.y[mask]\n",
    "        acc = int(correct.sum()) / int(mask.sum())\n",
    "    return acc\n",
    "\n",
    "num_epochs = 200\n",
    "best_val_acc_gat = 0\n",
    "best_model_gat = None\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    loss = train_gat()\n",
    "    train_acc = evaluate_gat(data.train_mask)\n",
    "    val_acc = evaluate_gat(data.val_mask)\n",
    "    if val_acc > best_val_acc_gat:\n",
    "        best_val_acc_gat = val_acc\n",
    "        best_model_gat = gat_model.state_dict()\n",
    "        torch.save(best_model_gat, os.path.join(output_dir, \"gat_best_model.pt\"))\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'GAT Epoch: {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
    "gat_training_time = time.time() - start_time\n",
    "gat_model.load_state_dict(best_model_gat)\n",
    "test_acc_gat = evaluate_gat(data.test_mask)\n",
    "print(f'GAT Test Accuracy: {test_acc_gat:.4f}')\n",
    "print(f'GAT Training Time: {gat_training_time:.2f} seconds')\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAT Epoch: 010, Loss: 1.2484, Train Acc: 0.8938, Val Acc: 0.8868\n",
      "GAT Epoch: 020, Loss: 0.9801, Train Acc: 0.5166, Val Acc: 0.5174\n",
      "GAT Epoch: 030, Loss: 0.8122, Train Acc: 0.6572, Val Acc: 0.6486\n",
      "GAT Epoch: 040, Loss: 0.6785, Train Acc: 0.7021, Val Acc: 0.7012\n",
      "GAT Epoch: 050, Loss: 0.6059, Train Acc: 0.7289, Val Acc: 0.7262\n",
      "GAT Epoch: 060, Loss: 0.5523, Train Acc: 0.7662, Val Acc: 0.7625\n",
      "GAT Epoch: 070, Loss: 0.5170, Train Acc: 0.7904, Val Acc: 0.7872\n",
      "GAT Epoch: 080, Loss: 0.4868, Train Acc: 0.8026, Val Acc: 0.8015\n",
      "GAT Epoch: 090, Loss: 0.4698, Train Acc: 0.8352, Val Acc: 0.8295\n",
      "GAT Epoch: 100, Loss: 0.4497, Train Acc: 0.8654, Val Acc: 0.8570\n",
      "GAT Epoch: 110, Loss: 0.4336, Train Acc: 0.8882, Val Acc: 0.8802\n",
      "GAT Epoch: 120, Loss: 0.4179, Train Acc: 0.8761, Val Acc: 0.8632\n",
      "GAT Epoch: 130, Loss: 0.4059, Train Acc: 0.9075, Val Acc: 0.8988\n",
      "GAT Epoch: 140, Loss: 0.3913, Train Acc: 0.9165, Val Acc: 0.9068\n",
      "GAT Epoch: 150, Loss: 0.3875, Train Acc: 0.9171, Val Acc: 0.9087\n",
      "GAT Epoch: 160, Loss: 0.3753, Train Acc: 0.9153, Val Acc: 0.9046\n",
      "GAT Epoch: 170, Loss: 0.3666, Train Acc: 0.9188, Val Acc: 0.9102\n",
      "GAT Epoch: 180, Loss: 0.3608, Train Acc: 0.9162, Val Acc: 0.9061\n",
      "GAT Epoch: 190, Loss: 0.3545, Train Acc: 0.9086, Val Acc: 0.8973\n",
      "GAT Epoch: 200, Loss: 0.3489, Train Acc: 0.9105, Val Acc: 0.8995\n",
      "GAT Test Accuracy: 0.9143\n",
      "GAT Training Time: 600.28 seconds\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## GraphSAGE"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T01:44:19.400444Z",
     "start_time": "2025-04-07T01:42:51.951897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(input_dim, hidden_dim)\n",
    "        self.conv2 = SAGEConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "sage_model = GraphSAGE(input_dim, hidden_dim, output_dim).to(device)\n",
    "optimizer_sage = torch.optim.Adam(sage_model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train_sage():\n",
    "    sage_model.train()\n",
    "    optimizer_sage.zero_grad()\n",
    "    out = sage_model(data)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer_sage.step()\n",
    "    return loss.item()\n",
    "\n",
    "def evaluate_sage(mask):\n",
    "    sage_model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = sage_model(data)\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct = pred[mask] == data.y[mask]\n",
    "        acc = int(correct.sum()) / int(mask.sum())\n",
    "    return acc\n",
    "\n",
    "num_epochs = 200\n",
    "best_val_acc_sage = 0\n",
    "best_model_sage = None\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    loss = train_sage()\n",
    "    train_acc = evaluate_sage(data.train_mask)\n",
    "    val_acc = evaluate_sage(data.val_mask)\n",
    "    if val_acc > best_val_acc_sage:\n",
    "        best_val_acc_sage = val_acc\n",
    "        best_model_sage = sage_model.state_dict()\n",
    "        # Save checkpoint in output folder\n",
    "        torch.save(best_model_sage, os.path.join(output_dir, \"sage_best_model.pt\"))\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'GraphSAGE Epoch: {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
    "sage_training_time = time.time() - start_time\n",
    "sage_model.load_state_dict(best_model_sage)\n",
    "test_acc_sage = evaluate_sage(data.test_mask)\n",
    "print(f'GraphSAGE Test Accuracy: {test_acc_sage:.4f}')\n",
    "print(f'GraphSAGE Training Time: {sage_training_time:.2f} seconds')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphSAGE Epoch: 010, Loss: 0.2511, Train Acc: 0.9148, Val Acc: 0.9055\n",
      "GraphSAGE Epoch: 020, Loss: 0.1781, Train Acc: 0.9390, Val Acc: 0.9317\n",
      "GraphSAGE Epoch: 030, Loss: 0.1513, Train Acc: 0.9582, Val Acc: 0.9570\n",
      "GraphSAGE Epoch: 040, Loss: 0.1333, Train Acc: 0.9658, Val Acc: 0.9669\n",
      "GraphSAGE Epoch: 050, Loss: 0.1209, Train Acc: 0.9695, Val Acc: 0.9712\n",
      "GraphSAGE Epoch: 060, Loss: 0.1124, Train Acc: 0.9723, Val Acc: 0.9727\n",
      "GraphSAGE Epoch: 070, Loss: 0.1062, Train Acc: 0.9739, Val Acc: 0.9749\n",
      "GraphSAGE Epoch: 080, Loss: 0.1007, Train Acc: 0.9757, Val Acc: 0.9757\n",
      "GraphSAGE Epoch: 090, Loss: 0.0956, Train Acc: 0.9768, Val Acc: 0.9768\n",
      "GraphSAGE Epoch: 100, Loss: 0.0914, Train Acc: 0.9778, Val Acc: 0.9779\n",
      "GraphSAGE Epoch: 110, Loss: 0.0899, Train Acc: 0.9788, Val Acc: 0.9779\n",
      "GraphSAGE Epoch: 120, Loss: 0.0861, Train Acc: 0.9798, Val Acc: 0.9792\n",
      "GraphSAGE Epoch: 130, Loss: 0.0841, Train Acc: 0.9803, Val Acc: 0.9787\n",
      "GraphSAGE Epoch: 140, Loss: 0.0796, Train Acc: 0.9806, Val Acc: 0.9792\n",
      "GraphSAGE Epoch: 150, Loss: 0.0783, Train Acc: 0.9810, Val Acc: 0.9794\n",
      "GraphSAGE Epoch: 160, Loss: 0.0762, Train Acc: 0.9817, Val Acc: 0.9809\n",
      "GraphSAGE Epoch: 170, Loss: 0.0752, Train Acc: 0.9819, Val Acc: 0.9800\n",
      "GraphSAGE Epoch: 180, Loss: 0.0720, Train Acc: 0.9820, Val Acc: 0.9802\n",
      "GraphSAGE Epoch: 190, Loss: 0.0751, Train Acc: 0.9827, Val Acc: 0.9820\n",
      "GraphSAGE Epoch: 200, Loss: 0.0715, Train Acc: 0.9823, Val Acc: 0.9800\n",
      "GraphSAGE Test Accuracy: 0.9760\n",
      "GraphSAGE Training Time: 87.29 seconds\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Subgraph Analysis Pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ----------- Subgraph Analysis Pipeline (Based on model output) -----------\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.utils import to_networkx\n",
    "import networkx as nx\n",
    "\n",
    "# Subgraph property analysis function\n",
    "def analyze_subgraph_properties(subgraph_nodes, model_output):\n",
    "    preds = model_output[subgraph_nodes].argmax(dim=1).cpu()\n",
    "\n",
    "    illicit_ratio = (preds == 1).sum().item() / len(preds)\n",
    "    licit_ratio = (preds == 2).sum().item() / len(preds)\n",
    "\n",
    "    return {\n",
    "        'num_nodes': len(subgraph_nodes),\n",
    "        'illicit_ratio': illicit_ratio,\n",
    "        'licit_ratio': licit_ratio\n",
    "    }\n",
    "\n",
    "# Full pipeline execution based on model output\n",
    "def pipeline(data, model, device='cpu', min_nodes=5):\n",
    "    model.eval()\n",
    "    data = data.to(device)\n",
    "\n",
    "    # Run model on full data\n",
    "    with torch.no_grad():\n",
    "        output = model(data)\n",
    "\n",
    "    # Convert to NetworkX graph\n",
    "    G_nx = to_networkx(data, to_undirected=True)\n",
    "\n",
    "    # Identify connected components\n",
    "    subgraphs = list(nx.connected_components(G_nx))\n",
    "\n",
    "    results = []\n",
    "    for nodes in subgraphs:\n",
    "        if len(nodes) < min_nodes:\n",
    "            continue\n",
    "        try:\n",
    "            node_indices = torch.tensor(list(nodes), dtype=torch.long)\n",
    "            res = analyze_subgraph_properties(node_indices, output)\n",
    "            results.append(res)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping subgraph due to error: {e}\")\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analysis for GAT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subgraph Statistics Summary:\n",
      "\n",
      "Total subgraphs: 49\n",
      "Average illicit ratio: 0.9851612683412899\n",
      "Average licit ratio: 0.0\n",
      "Average subgraph size: 4158.551020408163\n",
      "\n",
      "Distribution of subgraph sizes:\n",
      "count      49.000000\n",
      "mean     4158.551020\n",
      "std      1592.470592\n",
      "min      1089.000000\n",
      "25%      2891.000000\n",
      "50%      4291.000000\n",
      "75%      5121.000000\n",
      "max      7880.000000\n",
      "Name: num_nodes, dtype: float64\n",
      "\n",
      "Top 5 subgraphs with highest illicit ratio:\n",
      "    num_nodes  illicit_ratio  licit_ratio\n",
      "2        6621       0.999849          0.0\n",
      "0        7880       0.999492          0.0\n",
      "3        5693       0.999297          0.0\n",
      "1        4544       0.999120          0.0\n",
      "15       2975       0.998655          0.0\n",
      "\n",
      "Top 5 subgraphs with largest size:\n",
      "    num_nodes  illicit_ratio  licit_ratio\n",
      "0        7880       0.999492          0.0\n",
      "41       7140       0.981933          0.0\n",
      "4        6803       0.996619          0.0\n",
      "9        6727       0.996284          0.0\n",
      "2        6621       0.999849          0.0\n"
     ]
    }
   ],
   "source": [
    "results_df_GAT = pipeline(data, gat_model, device=device)\n",
    "\n",
    "# -------- Investigate Subgraph Patterns --------\n",
    "print(\"\\nSubgraph Statistics Summary:\\n\")\n",
    "print(\"Total subgraphs:\", len(results_df_GAT))\n",
    "print(\"Average illicit ratio:\", results_df_GAT['illicit_ratio'].mean())\n",
    "print(\"Average licit ratio:\", results_df_GAT['licit_ratio'].mean())\n",
    "print(\"Average subgraph size:\", results_df_GAT['num_nodes'].mean())\n",
    "\n",
    "print(\"\\nDistribution of subgraph sizes:\")\n",
    "print(results_df_GAT['num_nodes'].describe())\n",
    "\n",
    "print(\"\\nTop 5 subgraphs with highest illicit ratio:\")\n",
    "print(results_df_GAT.sort_values('illicit_ratio', ascending=False).head())\n",
    "\n",
    "print(\"\\nTop 5 subgraphs with largest size:\")\n",
    "print(results_df_GAT.sort_values('num_nodes', ascending=False).head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-07T02:11:29.846418Z",
     "start_time": "2025-04-07T02:11:28.710263Z"
    }
   },
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "source": [
    "Across the 49 connected subgraphs analyzed, the average illicit ratio is an exceptionally high 98.5%, with the licit ratio remaining at 0%. This indicates that nearly every node across all subgraphs is being classified as illicit by the GAT model. The average subgraph contains about 4,158 nodes, with the largest one having 7,880 nodes and the smallest 1,089. The top five subgraphs with the highest illicit ratios are all above 99.9%, suggesting near-total classification confidence by the model in labeling nodes as illicit. Notably, these top subgraphs are also among the largest by size, further amplifying their influence on the model’s output distribution.\n",
    "\n",
    "This extreme prediction skew implies that the GAT model has likely overfit to the illicit class, potentially due to training data imbalance or lack of expressive power to separate classes effectively. It may also reflect graph structural patterns where large components have highly correlated node labels. However, the complete absence of licit classifications is a red flag for model generalization and interpretability, and it calls for a deeper audit of the model’s training process, loss weighting strategy, and evaluation on balanced test data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analysis for Sega Graph\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subgraph Statistics Summary:\n",
      "\n",
      "Total subgraphs: 49\n",
      "Average illicit ratio: 0.9254265861926002\n",
      "Average licit ratio: 0.0\n",
      "Average subgraph size: 4158.551020408163\n",
      "\n",
      "Distribution of subgraph sizes:\n",
      "count      49.000000\n",
      "mean     4158.551020\n",
      "std      1592.470592\n",
      "min      1089.000000\n",
      "25%      2891.000000\n",
      "50%      4291.000000\n",
      "75%      5121.000000\n",
      "max      7880.000000\n",
      "Name: num_nodes, dtype: float64\n",
      "\n",
      "Top 5 subgraphs with highest illicit ratio:\n",
      "    num_nodes  illicit_ratio  licit_ratio\n",
      "2        6621       0.994261          0.0\n",
      "0        7880       0.994036          0.0\n",
      "1        4544       0.989217          0.0\n",
      "3        5693       0.988582          0.0\n",
      "44       5598       0.987853          0.0\n",
      "\n",
      "Top 5 subgraphs with largest size:\n",
      "    num_nodes  illicit_ratio  licit_ratio\n",
      "0        7880       0.994036          0.0\n",
      "41       7140       0.935994          0.0\n",
      "4        6803       0.982361          0.0\n",
      "9        6727       0.931768          0.0\n",
      "2        6621       0.994261          0.0\n"
     ]
    }
   ],
   "source": [
    "results_df_sage = pipeline(data, sage_model, device=device)\n",
    "\n",
    "# -------- Investigate Subgraph Patterns --------\n",
    "print(\"\\nSubgraph Statistics Summary:\\n\")\n",
    "print(\"Total subgraphs:\", len(results_df_sage))\n",
    "print(\"Average illicit ratio:\", results_df_sage['illicit_ratio'].mean())\n",
    "print(\"Average licit ratio:\", results_df_sage['licit_ratio'].mean())\n",
    "print(\"Average subgraph size:\", results_df_sage['num_nodes'].mean())\n",
    "\n",
    "print(\"\\nDistribution of subgraph sizes:\")\n",
    "print(results_df_sage['num_nodes'].describe())\n",
    "\n",
    "print(\"\\nTop 5 subgraphs with highest illicit ratio:\")\n",
    "print(results_df_sage.sort_values('illicit_ratio', ascending=False).head())\n",
    "\n",
    "print(\"\\nTop 5 subgraphs with largest size:\")\n",
    "print(results_df_sage.sort_values('num_nodes', ascending=False).head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-07T02:10:00.521179Z",
     "start_time": "2025-04-07T02:09:59.598950Z"
    }
   },
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "source": [
    "The analysis of the subgraph statistics reveals several notable patterns. Among the 49 connected subgraphs extracted from the graph, the average subgraph size is approximately 4,158 nodes, with the largest subgraph containing 7,880 nodes and the smallest having 1,089. Most strikingly, the average illicit ratio across all subgraphs is extremely high at approximately 92.5%, while the average licit ratio is effectively 0%. This indicates a strong imbalance in the model's output predictions, heavily skewed toward the \"illicit\" class. The top five subgraphs with the highest illicit ratios all exceed 98%, and they are also among the largest in terms of node count. This suggests that the largest components are not only dominant in size but are also classified almost entirely as illicit. Such a distribution might reflect the structure of the training data, potential class imbalance, or an overfitting tendency of the model to predict the illicit class. Further investigation is needed to verify whether this is due to real-world network patterns or modeling bias."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "    "
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
